{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Performance of 10 CV for ML models (significant CpGs limma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"10_CV_Results_RAWDATA\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>accuracy_train</th>\n",
       "      <th>accuracy_test</th>\n",
       "      <th>auc_train</th>\n",
       "      <th>auc_test</th>\n",
       "      <th>CpG_type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th>mval</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">SVM_c_RBF_15</th>\n",
       "      <th>Mval</th>\n",
       "      <td>0.927921</td>\n",
       "      <td>0.676322</td>\n",
       "      <td>0.988473</td>\n",
       "      <td>0.706140</td>\n",
       "      <td>Top 200 Limma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Betaval</th>\n",
       "      <td>0.677614</td>\n",
       "      <td>0.676015</td>\n",
       "      <td>0.772833</td>\n",
       "      <td>0.717524</td>\n",
       "      <td>Top 200 Limma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">SVM_c</th>\n",
       "      <th>Mval</th>\n",
       "      <td>0.851907</td>\n",
       "      <td>0.635363</td>\n",
       "      <td>0.901562</td>\n",
       "      <td>0.667028</td>\n",
       "      <td>Top 200 Limma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Betaval</th>\n",
       "      <td>0.762177</td>\n",
       "      <td>0.675277</td>\n",
       "      <td>0.850716</td>\n",
       "      <td>0.699290</td>\n",
       "      <td>Top 200 Limma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">RidgeLogisticRegr</th>\n",
       "      <th>Mval</th>\n",
       "      <td>0.841144</td>\n",
       "      <td>0.648155</td>\n",
       "      <td>0.914615</td>\n",
       "      <td>0.681009</td>\n",
       "      <td>Top 200 Limma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Betaval</th>\n",
       "      <td>0.749723</td>\n",
       "      <td>0.672632</td>\n",
       "      <td>0.826036</td>\n",
       "      <td>0.718921</td>\n",
       "      <td>Top 200 Limma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">RandomForest</th>\n",
       "      <th>Betaval</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.680197</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.725626</td>\n",
       "      <td>Top 200 Limma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mval</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.686654</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.730525</td>\n",
       "      <td>Top 200 Limma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">LogisticRegr</th>\n",
       "      <th>Mval</th>\n",
       "      <td>0.841943</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.915151</td>\n",
       "      <td>0.668571</td>\n",
       "      <td>Top 200 Limma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Betaval</th>\n",
       "      <td>0.836009</td>\n",
       "      <td>0.637761</td>\n",
       "      <td>0.910180</td>\n",
       "      <td>0.669829</td>\n",
       "      <td>Top 200 Limma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Lasso_classifier</th>\n",
       "      <th>Mval</th>\n",
       "      <td>0.807196</td>\n",
       "      <td>0.642927</td>\n",
       "      <td>0.881685</td>\n",
       "      <td>0.676609</td>\n",
       "      <td>Top 200 Limma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Betaval</th>\n",
       "      <td>0.753506</td>\n",
       "      <td>0.665744</td>\n",
       "      <td>0.829841</td>\n",
       "      <td>0.705814</td>\n",
       "      <td>Top 200 Limma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Elastic_net_classifier</th>\n",
       "      <th>Mval</th>\n",
       "      <td>0.812884</td>\n",
       "      <td>0.645756</td>\n",
       "      <td>0.887433</td>\n",
       "      <td>0.675241</td>\n",
       "      <td>Top 200 Limma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Betaval</th>\n",
       "      <td>0.748893</td>\n",
       "      <td>0.669373</td>\n",
       "      <td>0.826164</td>\n",
       "      <td>0.715678</td>\n",
       "      <td>Top 200 Limma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">DecisionTree</th>\n",
       "      <th>Mval</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.614760</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.602480</td>\n",
       "      <td>Top 200 Limma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Betaval</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.613715</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.600815</td>\n",
       "      <td>Top 200 Limma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">AdaBoost</th>\n",
       "      <th>Mval</th>\n",
       "      <td>0.870172</td>\n",
       "      <td>0.649016</td>\n",
       "      <td>0.950027</td>\n",
       "      <td>0.683232</td>\n",
       "      <td>Top 200 Limma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Betaval</th>\n",
       "      <td>0.858518</td>\n",
       "      <td>0.651845</td>\n",
       "      <td>0.943390</td>\n",
       "      <td>0.684425</td>\n",
       "      <td>Top 200 Limma</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                accuracy_train  accuracy_test  auc_train   \n",
       "model                  mval                                                \n",
       "SVM_c_RBF_15           Mval           0.927921       0.676322   0.988473  \\\n",
       "                       Betaval        0.677614       0.676015   0.772833   \n",
       "SVM_c                  Mval           0.851907       0.635363   0.901562   \n",
       "                       Betaval        0.762177       0.675277   0.850716   \n",
       "RidgeLogisticRegr      Mval           0.841144       0.648155   0.914615   \n",
       "                       Betaval        0.749723       0.672632   0.826036   \n",
       "RandomForest           Betaval        1.000000       0.680197   1.000000   \n",
       "                       Mval           1.000000       0.686654   1.000000   \n",
       "LogisticRegr           Mval           0.841943       0.633333   0.915151   \n",
       "                       Betaval        0.836009       0.637761   0.910180   \n",
       "Lasso_classifier       Mval           0.807196       0.642927   0.881685   \n",
       "                       Betaval        0.753506       0.665744   0.829841   \n",
       "Elastic_net_classifier Mval           0.812884       0.645756   0.887433   \n",
       "                       Betaval        0.748893       0.669373   0.826164   \n",
       "DecisionTree           Mval           1.000000       0.614760   1.000000   \n",
       "                       Betaval        1.000000       0.613715   1.000000   \n",
       "AdaBoost               Mval           0.870172       0.649016   0.950027   \n",
       "                       Betaval        0.858518       0.651845   0.943390   \n",
       "\n",
       "                                auc_test       CpG_type  \n",
       "model                  mval                              \n",
       "SVM_c_RBF_15           Mval     0.706140  Top 200 Limma  \n",
       "                       Betaval  0.717524  Top 200 Limma  \n",
       "SVM_c                  Mval     0.667028  Top 200 Limma  \n",
       "                       Betaval  0.699290  Top 200 Limma  \n",
       "RidgeLogisticRegr      Mval     0.681009  Top 200 Limma  \n",
       "                       Betaval  0.718921  Top 200 Limma  \n",
       "RandomForest           Betaval  0.725626  Top 200 Limma  \n",
       "                       Mval     0.730525  Top 200 Limma  \n",
       "LogisticRegr           Mval     0.668571  Top 200 Limma  \n",
       "                       Betaval  0.669829  Top 200 Limma  \n",
       "Lasso_classifier       Mval     0.676609  Top 200 Limma  \n",
       "                       Betaval  0.705814  Top 200 Limma  \n",
       "Elastic_net_classifier Mval     0.675241  Top 200 Limma  \n",
       "                       Betaval  0.715678  Top 200 Limma  \n",
       "DecisionTree           Mval     0.602480  Top 200 Limma  \n",
       "                       Betaval  0.600815  Top 200 Limma  \n",
       "AdaBoost               Mval     0.683232  Top 200 Limma  \n",
       "                       Betaval  0.684425  Top 200 Limma  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas\n",
    "from HelperScriptsPY import helper_functions\n",
    "\n",
    "base_dir = \"ML_CV_and_FINAL_RAW/10_CV_ML_Limma_CpGs\"\n",
    "model_folders = [base_dir + \"/\" + x for x in os.listdir(base_dir)]\n",
    "\n",
    "performance_lists = []\n",
    "\n",
    "for model_folder in model_folders:\n",
    "    CV_folders = [model_folder + \"/\" + x for x in os.listdir(model_folder)]\n",
    "    analysis_files = [x + \"/\" + i + \"/average_stats.csv\" for x in CV_folders for i in os.listdir(x)]\n",
    "\n",
    "    for path in analysis_files:\n",
    "        dataset = pandas.read_csv(path)\n",
    "        dataset[\"path\"] = path\n",
    "        performance_lists.append(dataset)\n",
    "\n",
    "\n",
    "performance_lists = pandas.concat(performance_lists)\n",
    "performance_lists =  performance_lists.groupby(['model', \"mval\"])[[\"accuracy_train\", \"accuracy_test\", \"auc_train\", \"auc_test\"]].mean()\n",
    "performance_lists = pandas.DataFrame(performance_lists)\n",
    "performance_lists[\"CpG_type\"] = \"Top 200 Limma\"\n",
    "performance_lists.to_csv(\"10_CV_Results_RAWDATA/10_CV_ML_Signif_CpGs_Limma_performance.csv\")\n",
    "performance_lists = performance_lists.sort_values(by=[\"model\"], ascending=False)\n",
    "performance_lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Performance of 10 CV for ML models (consistent CpGs (pre-selected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>accuracy_train</th>\n",
       "      <th>accuracy_test</th>\n",
       "      <th>auc_train</th>\n",
       "      <th>auc_test</th>\n",
       "      <th>CpG_type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th>mval</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">SVM_c_RBF_15</th>\n",
       "      <th>Mval</th>\n",
       "      <td>0.919065</td>\n",
       "      <td>0.727122</td>\n",
       "      <td>0.988364</td>\n",
       "      <td>0.789975</td>\n",
       "      <td>Top 200 Consistent (Pre-selected)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Betaval</th>\n",
       "      <td>0.676507</td>\n",
       "      <td>0.676507</td>\n",
       "      <td>0.731346</td>\n",
       "      <td>0.718519</td>\n",
       "      <td>Top 200 Consistent (Pre-selected)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">SVM_c</th>\n",
       "      <th>Mval</th>\n",
       "      <td>0.866851</td>\n",
       "      <td>0.730381</td>\n",
       "      <td>0.919874</td>\n",
       "      <td>0.801844</td>\n",
       "      <td>Top 200 Consistent (Pre-selected)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Betaval</th>\n",
       "      <td>0.746986</td>\n",
       "      <td>0.710148</td>\n",
       "      <td>0.850657</td>\n",
       "      <td>0.788984</td>\n",
       "      <td>Top 200 Consistent (Pre-selected)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">RidgeLogisticRegr</th>\n",
       "      <th>Mval</th>\n",
       "      <td>0.853167</td>\n",
       "      <td>0.739975</td>\n",
       "      <td>0.929971</td>\n",
       "      <td>0.814956</td>\n",
       "      <td>Top 200 Consistent (Pre-selected)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Betaval</th>\n",
       "      <td>0.748339</td>\n",
       "      <td>0.722017</td>\n",
       "      <td>0.825257</td>\n",
       "      <td>0.785657</td>\n",
       "      <td>Top 200 Consistent (Pre-selected)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">RandomForest</th>\n",
       "      <th>Betaval</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.707257</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>Top 200 Consistent (Pre-selected)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mval</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.708610</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.759905</td>\n",
       "      <td>Top 200 Consistent (Pre-selected)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">LogisticRegr</th>\n",
       "      <th>Mval</th>\n",
       "      <td>0.856365</td>\n",
       "      <td>0.732226</td>\n",
       "      <td>0.932485</td>\n",
       "      <td>0.800178</td>\n",
       "      <td>Top 200 Consistent (Pre-selected)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Betaval</th>\n",
       "      <td>0.852030</td>\n",
       "      <td>0.729520</td>\n",
       "      <td>0.929458</td>\n",
       "      <td>0.801667</td>\n",
       "      <td>Top 200 Consistent (Pre-selected)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Lasso_classifier</th>\n",
       "      <th>Mval</th>\n",
       "      <td>0.844988</td>\n",
       "      <td>0.738376</td>\n",
       "      <td>0.924185</td>\n",
       "      <td>0.815144</td>\n",
       "      <td>Top 200 Consistent (Pre-selected)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Betaval</th>\n",
       "      <td>0.737669</td>\n",
       "      <td>0.703137</td>\n",
       "      <td>0.813863</td>\n",
       "      <td>0.763951</td>\n",
       "      <td>Top 200 Consistent (Pre-selected)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Elastic_net_classifier</th>\n",
       "      <th>Mval</th>\n",
       "      <td>0.848831</td>\n",
       "      <td>0.738807</td>\n",
       "      <td>0.925574</td>\n",
       "      <td>0.816291</td>\n",
       "      <td>Top 200 Consistent (Pre-selected)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Betaval</th>\n",
       "      <td>0.740590</td>\n",
       "      <td>0.711993</td>\n",
       "      <td>0.816945</td>\n",
       "      <td>0.775028</td>\n",
       "      <td>Top 200 Consistent (Pre-selected)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">DecisionTree</th>\n",
       "      <th>Mval</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.621956</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.608879</td>\n",
       "      <td>Top 200 Consistent (Pre-selected)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Betaval</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.624477</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.612481</td>\n",
       "      <td>Top 200 Consistent (Pre-selected)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">AdaBoost</th>\n",
       "      <th>Mval</th>\n",
       "      <td>0.851876</td>\n",
       "      <td>0.680258</td>\n",
       "      <td>0.938498</td>\n",
       "      <td>0.736717</td>\n",
       "      <td>Top 200 Consistent (Pre-selected)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Betaval</th>\n",
       "      <td>0.849293</td>\n",
       "      <td>0.679028</td>\n",
       "      <td>0.937997</td>\n",
       "      <td>0.732918</td>\n",
       "      <td>Top 200 Consistent (Pre-selected)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                accuracy_train  accuracy_test  auc_train   \n",
       "model                  mval                                                \n",
       "SVM_c_RBF_15           Mval           0.919065       0.727122   0.988364  \\\n",
       "                       Betaval        0.676507       0.676507   0.731346   \n",
       "SVM_c                  Mval           0.866851       0.730381   0.919874   \n",
       "                       Betaval        0.746986       0.710148   0.850657   \n",
       "RidgeLogisticRegr      Mval           0.853167       0.739975   0.929971   \n",
       "                       Betaval        0.748339       0.722017   0.825257   \n",
       "RandomForest           Betaval        1.000000       0.707257   1.000000   \n",
       "                       Mval           1.000000       0.708610   1.000000   \n",
       "LogisticRegr           Mval           0.856365       0.732226   0.932485   \n",
       "                       Betaval        0.852030       0.729520   0.929458   \n",
       "Lasso_classifier       Mval           0.844988       0.738376   0.924185   \n",
       "                       Betaval        0.737669       0.703137   0.813863   \n",
       "Elastic_net_classifier Mval           0.848831       0.738807   0.925574   \n",
       "                       Betaval        0.740590       0.711993   0.816945   \n",
       "DecisionTree           Mval           1.000000       0.621956   1.000000   \n",
       "                       Betaval        1.000000       0.624477   1.000000   \n",
       "AdaBoost               Mval           0.851876       0.680258   0.938498   \n",
       "                       Betaval        0.849293       0.679028   0.937997   \n",
       "\n",
       "                                auc_test                           CpG_type  \n",
       "model                  mval                                                  \n",
       "SVM_c_RBF_15           Mval     0.789975  Top 200 Consistent (Pre-selected)  \n",
       "                       Betaval  0.718519  Top 200 Consistent (Pre-selected)  \n",
       "SVM_c                  Mval     0.801844  Top 200 Consistent (Pre-selected)  \n",
       "                       Betaval  0.788984  Top 200 Consistent (Pre-selected)  \n",
       "RidgeLogisticRegr      Mval     0.814956  Top 200 Consistent (Pre-selected)  \n",
       "                       Betaval  0.785657  Top 200 Consistent (Pre-selected)  \n",
       "RandomForest           Betaval  0.761589  Top 200 Consistent (Pre-selected)  \n",
       "                       Mval     0.759905  Top 200 Consistent (Pre-selected)  \n",
       "LogisticRegr           Mval     0.800178  Top 200 Consistent (Pre-selected)  \n",
       "                       Betaval  0.801667  Top 200 Consistent (Pre-selected)  \n",
       "Lasso_classifier       Mval     0.815144  Top 200 Consistent (Pre-selected)  \n",
       "                       Betaval  0.763951  Top 200 Consistent (Pre-selected)  \n",
       "Elastic_net_classifier Mval     0.816291  Top 200 Consistent (Pre-selected)  \n",
       "                       Betaval  0.775028  Top 200 Consistent (Pre-selected)  \n",
       "DecisionTree           Mval     0.608879  Top 200 Consistent (Pre-selected)  \n",
       "                       Betaval  0.612481  Top 200 Consistent (Pre-selected)  \n",
       "AdaBoost               Mval     0.736717  Top 200 Consistent (Pre-selected)  \n",
       "                       Betaval  0.732918  Top 200 Consistent (Pre-selected)  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas\n",
    "from HelperScriptsPY import helper_functions\n",
    "\n",
    "base_dir = \"ML_CV_and_FINAL_RAW/10_CV_ML_200_ALL_consistent_CpGs\"\n",
    "model_folders = [base_dir + \"/\" + x for x in os.listdir(base_dir)]\n",
    "\n",
    "performance_lists = []\n",
    "\n",
    "for model_folder in model_folders:\n",
    "    CV_folders = [model_folder + \"/\" + x for x in os.listdir(model_folder)]\n",
    "    analysis_files = [x + \"/\" + i + \"/average_stats.csv\" for x in CV_folders for i in os.listdir(x)]\n",
    "\n",
    "    for path in analysis_files:\n",
    "        dataset = pandas.read_csv(path)\n",
    "        dataset[\"path\"] = path\n",
    "        performance_lists.append(dataset)\n",
    "\n",
    "\n",
    "performance_lists = pandas.concat(performance_lists)\n",
    "performance_lists =  performance_lists.groupby(['model', \"mval\"])[[\"accuracy_train\", \"accuracy_test\", \"auc_train\", \"auc_test\"]].mean()\n",
    "performance_lists = pandas.DataFrame(performance_lists)\n",
    "performance_lists[\"CpG_type\"] = \"Top 200 Consistent (Pre-selected)\"\n",
    "performance_lists.to_csv(\"10_CV_Results_RAWDATA/10_CV_ML_Consistent_CpGs_performance.csv\")\n",
    "performance_lists = performance_lists.sort_values(by=[\"model\"], ascending=False)\n",
    "performance_lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance of Ridge regression, Lasso, and Elastic net classifiers from top 10K limma CpGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>accuracy_train</th>\n",
       "      <th>accuracy_test</th>\n",
       "      <th>auc_train</th>\n",
       "      <th>auc_test</th>\n",
       "      <th>CpG_type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th>mval</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">RidgeLogisticRegr</th>\n",
       "      <th>Betaval</th>\n",
       "      <td>0.997970</td>\n",
       "      <td>0.660332</td>\n",
       "      <td>0.999386</td>\n",
       "      <td>0.701385</td>\n",
       "      <td>Top 10K Limma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mval</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.667036</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.698888</td>\n",
       "      <td>Top 10K Limma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Lasso_classifier</th>\n",
       "      <th>Betaval</th>\n",
       "      <td>0.940375</td>\n",
       "      <td>0.656827</td>\n",
       "      <td>0.986746</td>\n",
       "      <td>0.693990</td>\n",
       "      <td>Top 10K Limma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mval</th>\n",
       "      <td>0.999477</td>\n",
       "      <td>0.668143</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.707976</td>\n",
       "      <td>Top 10K Limma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Elastic_net_classifier</th>\n",
       "      <th>Betaval</th>\n",
       "      <td>0.970695</td>\n",
       "      <td>0.667958</td>\n",
       "      <td>0.995711</td>\n",
       "      <td>0.706119</td>\n",
       "      <td>Top 10K Limma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mval</th>\n",
       "      <td>0.999938</td>\n",
       "      <td>0.667835</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.706557</td>\n",
       "      <td>Top 10K Limma</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                accuracy_train  accuracy_test  auc_train   \n",
       "model                  mval                                                \n",
       "RidgeLogisticRegr      Betaval        0.997970       0.660332   0.999386  \\\n",
       "                       Mval           1.000000       0.667036   1.000000   \n",
       "Lasso_classifier       Betaval        0.940375       0.656827   0.986746   \n",
       "                       Mval           0.999477       0.668143   0.999997   \n",
       "Elastic_net_classifier Betaval        0.970695       0.667958   0.995711   \n",
       "                       Mval           0.999938       0.667835   1.000000   \n",
       "\n",
       "                                auc_test       CpG_type  \n",
       "model                  mval                              \n",
       "RidgeLogisticRegr      Betaval  0.701385  Top 10K Limma  \n",
       "                       Mval     0.698888  Top 10K Limma  \n",
       "Lasso_classifier       Betaval  0.693990  Top 10K Limma  \n",
       "                       Mval     0.707976  Top 10K Limma  \n",
       "Elastic_net_classifier Betaval  0.706119  Top 10K Limma  \n",
       "                       Mval     0.706557  Top 10K Limma  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas\n",
    "from HelperScriptsPY import helper_functions\n",
    "\n",
    "base_dir = \"ML_CV_and_FINAL_RAW/10_CV_ML_10K_Limma\"\n",
    "model_folders = [base_dir + \"/\" + x for x in os.listdir(base_dir)]\n",
    "\n",
    "performance_lists = []\n",
    "\n",
    "for model_folder in model_folders:\n",
    "    CV_folders = [model_folder + \"/\" + x for x in os.listdir(model_folder)]\n",
    "    analysis_files = [x + \"/\" + i + \"/average_stats.csv\" for x in CV_folders for i in os.listdir(x)]\n",
    "\n",
    "    for path in analysis_files:\n",
    "        dataset = pandas.read_csv(path)\n",
    "        dataset[\"path\"] = path\n",
    "        performance_lists.append(dataset)\n",
    "\n",
    "\n",
    "performance_lists = pandas.concat(performance_lists)\n",
    "performance_lists =  performance_lists.groupby(['model', \"mval\"])[[\"accuracy_train\", \"accuracy_test\", \"auc_train\", \"auc_test\"]].mean()\n",
    "performance_lists = pandas.DataFrame(performance_lists)\n",
    "performance_lists[\"CpG_type\"] = \"Top 10K Limma\"\n",
    "performance_lists.to_csv(\"10_CV_Results_RAWDATA/10_CV_ML_10K_Limma_performance.csv\")\n",
    "performance_lists = performance_lists.sort_values(by=[\"model\"], ascending=False)\n",
    "performance_lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance of 10 CV JointAE-classifier (limma and consistent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>epochs</th>\n",
       "      <th>total_folds</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>mval</th>\n",
       "      <th>balance_alpha</th>\n",
       "      <th>cpg_type</th>\n",
       "      <th>limma_features</th>\n",
       "      <th>outer_cls_activ</th>\n",
       "      <th>outer_ae_activ</th>\n",
       "      <th>...</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>drop_rate</th>\n",
       "      <th>classif_loss_fun</th>\n",
       "      <th>recon_loss_fun</th>\n",
       "      <th>batch_normal</th>\n",
       "      <th>kernel_regular</th>\n",
       "      <th>accuracy_train</th>\n",
       "      <th>accuracy_test</th>\n",
       "      <th>auc_train</th>\n",
       "      <th>auc_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JointAE-classifier</td>\n",
       "      <td>2000</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>0.1</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>linear</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>BN</td>\n",
       "      <td>l1_l2</td>\n",
       "      <td>0.873678</td>\n",
       "      <td>0.646679</td>\n",
       "      <td>0.905928</td>\n",
       "      <td>0.654742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                model epochs total_folds batch_size  mval balance_alpha   \n",
       "0  JointAE-classifier   2000           3        128  Mval           0.1  \\\n",
       "\n",
       "  cpg_type limma_features outer_cls_activ outer_ae_activ  ... learning_rate   \n",
       "0      ALL            200         sigmoid         linear  ...        0.0001  \\\n",
       "\n",
       "  drop_rate     classif_loss_fun      recon_loss_fun batch_normal   \n",
       "0       0.1  binary_crossentropy  mean_squared_error           BN  \\\n",
       "\n",
       "  kernel_regular accuracy_train  accuracy_test  auc_train  auc_test  \n",
       "0          l1_l2       0.873678       0.646679   0.905928  0.654742  \n",
       "\n",
       "[1 rows x 21 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas\n",
    "from HelperScriptsPY import helper_functions\n",
    "\n",
    "base_dir = \"10CV_DNN_RAW/10_CV_JointAE\"\n",
    "CV_folders = [base_dir + \"/\" + x for x in os.listdir(base_dir) if os.path.isdir(base_dir + \"/\" + x)]\n",
    "performance_lists = []\n",
    "\n",
    "for x in CV_folders:\n",
    "    sub_folder = os.listdir(x)[0]\n",
    "    path = x + \"/\" + sub_folder + \"/\" + \"average_stats.csv\"\n",
    "    dataset = pandas.read_csv(path)\n",
    "    dataset = helper_functions.drop_useless_column(dataset)\n",
    "    performance_lists.append(dataset)\n",
    "\n",
    "performance_df = pandas.concat(performance_lists)\n",
    "output_stats =  performance_df[[\"accuracy_train\", \"accuracy_test\", \"auc_train\", \"auc_test\"]].mean()\n",
    "output_stats = pandas.DataFrame(output_stats)\n",
    "output_stats = output_stats.transpose()\n",
    "\n",
    "output_stats_base_info = performance_df.drop([\"accuracy_train\",\n",
    "                                       \"accuracy_test\", \n",
    "                                       \"auc_train\", \n",
    "                                       \"auc_test\",\n",
    "                                       \"roc_auc_plot_test\"] , axis=1)\n",
    "output_stats_base_info = output_stats_base_info.iloc[0]\n",
    "output_stats_base_info = pandas.DataFrame(output_stats_base_info)\n",
    "output_stats_base_info = output_stats_base_info.transpose()\n",
    "output_stats = pandas.concat([output_stats_base_info, output_stats], axis=1)\n",
    "output_stats[\"model\"] = \"JointAE-classifier\"\n",
    "output_stats.to_csv(\"10_CV_Results_RAWDATA/10_CV_JointAE.csv\")\n",
    "output_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>epochs</th>\n",
       "      <th>total_folds</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>mval</th>\n",
       "      <th>balance_alpha</th>\n",
       "      <th>cpg_type</th>\n",
       "      <th>limma_features</th>\n",
       "      <th>outer_cls_activ</th>\n",
       "      <th>outer_ae_activ</th>\n",
       "      <th>...</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>drop_rate</th>\n",
       "      <th>classif_loss_fun</th>\n",
       "      <th>recon_loss_fun</th>\n",
       "      <th>batch_normal</th>\n",
       "      <th>kernel_regular</th>\n",
       "      <th>accuracy_train</th>\n",
       "      <th>accuracy_test</th>\n",
       "      <th>auc_train</th>\n",
       "      <th>auc_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JointAE-classifier</td>\n",
       "      <td>2000</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Top_200_all_consistent_CpGs.txt</td>\n",
       "      <td>200</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>linear</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>BN</td>\n",
       "      <td>l1_l2</td>\n",
       "      <td>0.865775</td>\n",
       "      <td>0.711132</td>\n",
       "      <td>0.900864</td>\n",
       "      <td>0.724077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                model epochs total_folds batch_size  mval balance_alpha   \n",
       "0  JointAE-classifier   2000           3        128  Mval           0.1  \\\n",
       "\n",
       "                          cpg_type limma_features outer_cls_activ   \n",
       "0  Top_200_all_consistent_CpGs.txt            200         sigmoid  \\\n",
       "\n",
       "  outer_ae_activ  ... learning_rate drop_rate     classif_loss_fun   \n",
       "0         linear  ...        0.0001       0.1  binary_crossentropy  \\\n",
       "\n",
       "       recon_loss_fun batch_normal kernel_regular accuracy_train   \n",
       "0  mean_squared_error           BN          l1_l2       0.865775  \\\n",
       "\n",
       "   accuracy_test  auc_train  auc_test  \n",
       "0       0.711132   0.900864  0.724077  \n",
       "\n",
       "[1 rows x 21 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas\n",
    "from HelperScriptsPY import helper_functions\n",
    "\n",
    "base_dir = \"10CV_DNN_RAW/10_CV_JointAE_consistent\"\n",
    "CV_folders = [base_dir + \"/\" + x for x in os.listdir(base_dir) if os.path.isdir(base_dir + \"/\" + x)]\n",
    "performance_lists = []\n",
    "\n",
    "for x in CV_folders:\n",
    "    sub_folder = os.listdir(x)[0]\n",
    "    path = x + \"/\" + sub_folder + \"/\" + \"average_stats.csv\"\n",
    "    dataset = pandas.read_csv(path)\n",
    "    dataset = helper_functions.drop_useless_column(dataset)\n",
    "    performance_lists.append(dataset)\n",
    "\n",
    "performance_df = pandas.concat(performance_lists)\n",
    "output_stats =  performance_df[[\"accuracy_train\", \"accuracy_test\", \"auc_train\", \"auc_test\"]].mean()\n",
    "output_stats = pandas.DataFrame(output_stats)\n",
    "output_stats = output_stats.transpose()\n",
    "\n",
    "output_stats_base_info = performance_df.drop([\"accuracy_train\",\n",
    "                                       \"accuracy_test\", \n",
    "                                       \"auc_train\", \n",
    "                                       \"auc_test\",\n",
    "                                       \"roc_auc_plot_test\"] , axis=1)\n",
    "output_stats_base_info = output_stats_base_info.iloc[0]\n",
    "output_stats_base_info = pandas.DataFrame(output_stats_base_info)\n",
    "output_stats_base_info = output_stats_base_info.transpose()\n",
    "output_stats = pandas.concat([output_stats_base_info, output_stats], axis=1)\n",
    "output_stats[\"model\"] = \"JointAE-classifier\"\n",
    "output_stats.to_csv(\"10_CV_Results_RAWDATA/10_CV_JointAE_consistent.csv\")\n",
    "output_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance of 10CV JointVAE-classifier (limma and consistent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>epochs</th>\n",
       "      <th>total_folds</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>mval</th>\n",
       "      <th>balance_alpha</th>\n",
       "      <th>cpg_type</th>\n",
       "      <th>limma_features</th>\n",
       "      <th>outer_cls_activ</th>\n",
       "      <th>outer_ae_activ</th>\n",
       "      <th>...</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>drop_rate</th>\n",
       "      <th>classif_loss_fun</th>\n",
       "      <th>recon_loss_fun</th>\n",
       "      <th>batch_normal</th>\n",
       "      <th>kernel_regular</th>\n",
       "      <th>accuracy_train</th>\n",
       "      <th>accuracy_test</th>\n",
       "      <th>auc_train</th>\n",
       "      <th>auc_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JointVAE-classifier</td>\n",
       "      <td>2250</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>tanh</td>\n",
       "      <td>linear</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>BN</td>\n",
       "      <td>l1_l2</td>\n",
       "      <td>0.979028</td>\n",
       "      <td>0.627798</td>\n",
       "      <td>0.975102</td>\n",
       "      <td>0.651361</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model epochs total_folds batch_size  mval balance_alpha   \n",
       "0  JointVAE-classifier   2250           3        128  Mval           1.0  \\\n",
       "\n",
       "  cpg_type limma_features outer_cls_activ outer_ae_activ  ... learning_rate   \n",
       "0      ALL            200            tanh         linear  ...        0.0001  \\\n",
       "\n",
       "  drop_rate classif_loss_fun      recon_loss_fun batch_normal kernel_regular   \n",
       "0       0.1    squared_hinge  mean_squared_error           BN          l1_l2  \\\n",
       "\n",
       "  accuracy_train  accuracy_test  auc_train  auc_test  \n",
       "0       0.979028       0.627798   0.975102  0.651361  \n",
       "\n",
       "[1 rows x 21 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas\n",
    "from HelperScriptsPY import helper_functions\n",
    "\n",
    "base_dir = \"10CV_DNN_RAW/10_CV_JointVAE\"\n",
    "CV_folders = [base_dir + \"/\" + x for x in os.listdir(base_dir) if os.path.isdir(base_dir + \"/\" + x)]\n",
    "performance_lists = []\n",
    "\n",
    "for x in CV_folders:\n",
    "    sub_folder = os.listdir(x)[0]\n",
    "    path = x + \"/\" + sub_folder + \"/\" + \"average_stats.csv\"\n",
    "    dataset = pandas.read_csv(path)\n",
    "    dataset = helper_functions.drop_useless_column(dataset)\n",
    "    performance_lists.append(dataset)\n",
    "\n",
    "performance_df = pandas.concat(performance_lists)\n",
    "output_stats =  performance_df[[\"accuracy_train\", \"accuracy_test\", \"auc_train\", \"auc_test\"]].mean()\n",
    "output_stats = pandas.DataFrame(output_stats)\n",
    "output_stats = output_stats.transpose()\n",
    "\n",
    "output_stats_base_info = performance_df.drop([\"accuracy_train\",\n",
    "                                       \"accuracy_test\", \n",
    "                                       \"auc_train\", \n",
    "                                       \"auc_test\",\n",
    "                                       \"roc_auc_plot_test\"] , axis=1)\n",
    "output_stats_base_info = output_stats_base_info.iloc[0]\n",
    "output_stats_base_info = pandas.DataFrame(output_stats_base_info)\n",
    "output_stats_base_info = output_stats_base_info.transpose()\n",
    "output_stats = pandas.concat([output_stats_base_info, output_stats], axis=1)\n",
    "output_stats[\"model\"] = \"JointVAE-classifier\"\n",
    "output_stats.to_csv(\"10_CV_Results_RAWDATA/10_CV_JointVAE.csv\")\n",
    "output_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>epochs</th>\n",
       "      <th>total_folds</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>mval</th>\n",
       "      <th>balance_alpha</th>\n",
       "      <th>cpg_type</th>\n",
       "      <th>limma_features</th>\n",
       "      <th>outer_cls_activ</th>\n",
       "      <th>outer_ae_activ</th>\n",
       "      <th>...</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>drop_rate</th>\n",
       "      <th>classif_loss_fun</th>\n",
       "      <th>recon_loss_fun</th>\n",
       "      <th>batch_normal</th>\n",
       "      <th>kernel_regular</th>\n",
       "      <th>accuracy_train</th>\n",
       "      <th>accuracy_test</th>\n",
       "      <th>auc_train</th>\n",
       "      <th>auc_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JointVAE-classifier</td>\n",
       "      <td>2250</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Top_200_all_consistent_CpGs.txt</td>\n",
       "      <td>200</td>\n",
       "      <td>tanh</td>\n",
       "      <td>linear</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>BN</td>\n",
       "      <td>l1_l2</td>\n",
       "      <td>0.982011</td>\n",
       "      <td>0.706642</td>\n",
       "      <td>0.978027</td>\n",
       "      <td>0.771627</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model epochs total_folds batch_size  mval balance_alpha   \n",
       "0  JointVAE-classifier   2250           3        128  Mval           1.0  \\\n",
       "\n",
       "                          cpg_type limma_features outer_cls_activ   \n",
       "0  Top_200_all_consistent_CpGs.txt            200            tanh  \\\n",
       "\n",
       "  outer_ae_activ  ... learning_rate drop_rate classif_loss_fun   \n",
       "0         linear  ...        0.0001       0.1    squared_hinge  \\\n",
       "\n",
       "       recon_loss_fun batch_normal kernel_regular accuracy_train   \n",
       "0  mean_squared_error           BN          l1_l2       0.982011  \\\n",
       "\n",
       "   accuracy_test  auc_train  auc_test  \n",
       "0       0.706642   0.978027  0.771627  \n",
       "\n",
       "[1 rows x 21 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas\n",
    "from HelperScriptsPY import helper_functions\n",
    "\n",
    "base_dir = \"10CV_DNN_RAW/10_CV_JointVAE_consistent\"\n",
    "CV_folders = [base_dir + \"/\" + x for x in os.listdir(base_dir) if os.path.isdir(base_dir + \"/\" + x)]\n",
    "performance_lists = []\n",
    "\n",
    "for x in CV_folders:\n",
    "    sub_folder = os.listdir(x)[0]\n",
    "    path = x + \"/\" + sub_folder + \"/\" + \"average_stats.csv\"\n",
    "    dataset = pandas.read_csv(path)\n",
    "    dataset = helper_functions.drop_useless_column(dataset)\n",
    "    performance_lists.append(dataset)\n",
    "\n",
    "performance_df = pandas.concat(performance_lists)\n",
    "output_stats =  performance_df[[\"accuracy_train\", \"accuracy_test\", \"auc_train\", \"auc_test\"]].mean()\n",
    "output_stats = pandas.DataFrame(output_stats)\n",
    "output_stats = output_stats.transpose()\n",
    "\n",
    "output_stats_base_info = performance_df.drop([\"accuracy_train\",\n",
    "                                       \"accuracy_test\", \n",
    "                                       \"auc_train\", \n",
    "                                       \"auc_test\",\n",
    "                                       \"roc_auc_plot_test\"] , axis=1)\n",
    "output_stats_base_info = output_stats_base_info.iloc[0]\n",
    "output_stats_base_info = pandas.DataFrame(output_stats_base_info)\n",
    "output_stats_base_info = output_stats_base_info.transpose()\n",
    "output_stats = pandas.concat([output_stats_base_info, output_stats], axis=1)\n",
    "output_stats[\"model\"]= \"JointVAE-classifier\"\n",
    "output_stats.to_csv(\"10_CV_Results_RAWDATA/10_CV_JointVAE_consistent.csv\")\n",
    "output_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance of 10CV Small DNN (limma and consistent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>epochs</th>\n",
       "      <th>total_folds</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>mval</th>\n",
       "      <th>cpg_type</th>\n",
       "      <th>limma_features</th>\n",
       "      <th>outer_cls_activ</th>\n",
       "      <th>inner_act</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>classif_loss_fun</th>\n",
       "      <th>roc_auc_plot_test</th>\n",
       "      <th>accuracy_train</th>\n",
       "      <th>accuracy_test</th>\n",
       "      <th>auc_train</th>\n",
       "      <th>auc_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DNN classifier</td>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>0.682367</td>\n",
       "      <td>0.999569</td>\n",
       "      <td>0.63813</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.671635</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            model epochs total_folds batch_size  mval cpg_type limma_features   \n",
       "0  DNN classifier   1000           3        128  Mval      ALL            200  \\\n",
       "\n",
       "  outer_cls_activ inner_act learning_rate     classif_loss_fun   \n",
       "0         sigmoid      relu        0.0001  binary_crossentropy  \\\n",
       "\n",
       "  roc_auc_plot_test  accuracy_train  accuracy_test  auc_train  auc_test  \n",
       "0          0.682367        0.999569        0.63813   0.999998  0.671635  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas\n",
    "from HelperScriptsPY import helper_functions\n",
    "\n",
    "base_dir = \"10CV_DNN_RAW/10_CV_SmallDNN\"\n",
    "CV_folders = [base_dir + \"/\" + x for x in os.listdir(base_dir) if os.path.isdir(base_dir + \"/\" + x)]\n",
    "performance_lists = []\n",
    "\n",
    "for x in CV_folders:\n",
    "    sub_folder = os.listdir(x)[0]\n",
    "    path = x + \"/\" + sub_folder + \"/\" + \"average_stats.csv\"\n",
    "    dataset = pandas.read_csv(path)\n",
    "    dataset = helper_functions.drop_useless_column(dataset)\n",
    "    performance_lists.append(dataset)\n",
    "\n",
    "performance_df = pandas.concat(performance_lists)\n",
    "output_stats =  performance_df[[\"accuracy_train\", \"accuracy_test\", \"auc_train\", \"auc_test\"]].mean()\n",
    "output_stats = pandas.DataFrame(output_stats)\n",
    "output_stats = output_stats.transpose()\n",
    "\n",
    "output_stats_base_info = performance_df.drop([\"accuracy_train\",\n",
    "                                       \"accuracy_test\", \n",
    "                                       \"auc_train\", \n",
    "                                       \"auc_test\"] , axis=1)\n",
    "output_stats_base_info = output_stats_base_info.iloc[0]\n",
    "output_stats_base_info = pandas.DataFrame(output_stats_base_info)\n",
    "output_stats_base_info = output_stats_base_info.transpose()\n",
    "output_stats = pandas.concat([output_stats_base_info, output_stats], axis=1)\n",
    "output_stats[\"model\"] = \"DNN classifier\"\n",
    "output_stats.to_csv(\"10_CV_Results_RAWDATA/10_CV_SmallDNN.csv\")\n",
    "output_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>epochs</th>\n",
       "      <th>total_folds</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>mval</th>\n",
       "      <th>cpg_type</th>\n",
       "      <th>limma_features</th>\n",
       "      <th>outer_cls_activ</th>\n",
       "      <th>inner_act</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>classif_loss_fun</th>\n",
       "      <th>roc_auc_plot_test</th>\n",
       "      <th>accuracy_train</th>\n",
       "      <th>accuracy_test</th>\n",
       "      <th>auc_train</th>\n",
       "      <th>auc_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DNN classifier</td>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>Top_200_all_consistent_CpGs.txt</td>\n",
       "      <td>200</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>0.764994</td>\n",
       "      <td>0.999477</td>\n",
       "      <td>0.707565</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.770537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            model epochs total_folds batch_size  mval   \n",
       "0  DNN classifier   1000           3        128  Mval  \\\n",
       "\n",
       "                          cpg_type limma_features outer_cls_activ inner_act   \n",
       "0  Top_200_all_consistent_CpGs.txt            200         sigmoid      relu  \\\n",
       "\n",
       "  learning_rate     classif_loss_fun roc_auc_plot_test  accuracy_train   \n",
       "0        0.0001  binary_crossentropy          0.764994        0.999477  \\\n",
       "\n",
       "   accuracy_test  auc_train  auc_test  \n",
       "0       0.707565   0.999985  0.770537  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas\n",
    "from HelperScriptsPY import helper_functions\n",
    "\n",
    "base_dir = \"10CV_DNN_RAW/10_CV_SmallDNN_consistent\"\n",
    "CV_folders = [base_dir + \"/\" + x for x in os.listdir(base_dir) if os.path.isdir(base_dir + \"/\" + x)]\n",
    "performance_lists = []\n",
    "\n",
    "for x in CV_folders:\n",
    "    sub_folder = os.listdir(x)[0]\n",
    "    path = x + \"/\" + sub_folder + \"/\" + \"average_stats.csv\"\n",
    "    dataset = pandas.read_csv(path)\n",
    "    dataset = helper_functions.drop_useless_column(dataset)\n",
    "    performance_lists.append(dataset)\n",
    "\n",
    "performance_df = pandas.concat(performance_lists)\n",
    "output_stats =  performance_df[[\"accuracy_train\", \"accuracy_test\", \"auc_train\", \"auc_test\"]].mean()\n",
    "output_stats = pandas.DataFrame(output_stats)\n",
    "output_stats = output_stats.transpose()\n",
    "\n",
    "output_stats_base_info = performance_df.drop([\"accuracy_train\",\n",
    "                                       \"accuracy_test\", \n",
    "                                       \"auc_train\", \n",
    "                                       \"auc_test\"] , axis=1)\n",
    "output_stats_base_info = output_stats_base_info.iloc[0]\n",
    "output_stats_base_info = pandas.DataFrame(output_stats_base_info)\n",
    "output_stats_base_info = output_stats_base_info.transpose()\n",
    "output_stats = pandas.concat([output_stats_base_info, output_stats], axis=1)\n",
    "output_stats[\"model\"] = \"DNN classifier\"\n",
    "output_stats.to_csv(\"10_CV_Results_RAWDATA/10_CV_SmallDNN_consistent.csv\")\n",
    "output_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating fold data for figure S5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>model</th>\n",
       "      <th>fold</th>\n",
       "      <th>total_folds</th>\n",
       "      <th>mval</th>\n",
       "      <th>cpg_type</th>\n",
       "      <th>limma_features</th>\n",
       "      <th>accuracy_train</th>\n",
       "      <th>accuracy_test</th>\n",
       "      <th>auc_train</th>\n",
       "      <th>auc_test</th>\n",
       "      <th>roc_auc_plot_test</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>SVM_c_RBF_15</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Betaval</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>0.678044</td>\n",
       "      <td>0.675277</td>\n",
       "      <td>0.768813</td>\n",
       "      <td>0.704630</td>\n",
       "      <td>0.704630</td>\n",
       "      <td>ML_CV_and_FINAL_RAW/10_CV_ML_Limma_CpGs/SVM_c_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>SVM_c_RBF_15</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Betaval</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>0.673432</td>\n",
       "      <td>0.682657</td>\n",
       "      <td>0.792484</td>\n",
       "      <td>0.743991</td>\n",
       "      <td>0.743991</td>\n",
       "      <td>ML_CV_and_FINAL_RAW/10_CV_ML_Limma_CpGs/SVM_c_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>SVM_c_RBF_15</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Betaval</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>0.677122</td>\n",
       "      <td>0.673432</td>\n",
       "      <td>0.762806</td>\n",
       "      <td>0.702658</td>\n",
       "      <td>0.702658</td>\n",
       "      <td>ML_CV_and_FINAL_RAW/10_CV_ML_Limma_CpGs/SVM_c_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>SVM_c_RBF_15</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Mval</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>0.944649</td>\n",
       "      <td>0.671587</td>\n",
       "      <td>0.989190</td>\n",
       "      <td>0.709857</td>\n",
       "      <td>0.709857</td>\n",
       "      <td>ML_CV_and_FINAL_RAW/10_CV_ML_Limma_CpGs/SVM_c_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>SVM_c_RBF_15</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Mval</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>0.868081</td>\n",
       "      <td>0.688192</td>\n",
       "      <td>0.976227</td>\n",
       "      <td>0.716739</td>\n",
       "      <td>0.716739</td>\n",
       "      <td>ML_CV_and_FINAL_RAW/10_CV_ML_Limma_CpGs/SVM_c_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Betaval</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.684502</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750130</td>\n",
       "      <td>0.750130</td>\n",
       "      <td>ML_CV_and_FINAL_RAW/10_CV_ML_Limma_CpGs/Random...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Betaval</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.675277</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.718329</td>\n",
       "      <td>0.718329</td>\n",
       "      <td>ML_CV_and_FINAL_RAW/10_CV_ML_Limma_CpGs/Random...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Mval</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.686347</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.748313</td>\n",
       "      <td>0.748313</td>\n",
       "      <td>ML_CV_and_FINAL_RAW/10_CV_ML_Limma_CpGs/Random...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Mval</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.695572</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.725656</td>\n",
       "      <td>0.725656</td>\n",
       "      <td>ML_CV_and_FINAL_RAW/10_CV_ML_Limma_CpGs/Random...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Mval</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.678967</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.709449</td>\n",
       "      <td>0.709449</td>\n",
       "      <td>ML_CV_and_FINAL_RAW/10_CV_ML_Limma_CpGs/Random...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>540 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0         model  fold  total_folds     mval cpg_type   \n",
       "0            0  SVM_c_RBF_15     3            3  Betaval      ALL  \\\n",
       "0            0  SVM_c_RBF_15     2            3  Betaval      ALL   \n",
       "0            0  SVM_c_RBF_15     1            3  Betaval      ALL   \n",
       "0            0  SVM_c_RBF_15     3            3     Mval      ALL   \n",
       "0            0  SVM_c_RBF_15     2            3     Mval      ALL   \n",
       "..         ...           ...   ...          ...      ...      ...   \n",
       "0            0  RandomForest     2            3  Betaval      ALL   \n",
       "0            0  RandomForest     1            3  Betaval      ALL   \n",
       "0            0  RandomForest     3            3     Mval      ALL   \n",
       "0            0  RandomForest     2            3     Mval      ALL   \n",
       "0            0  RandomForest     1            3     Mval      ALL   \n",
       "\n",
       "    limma_features  accuracy_train  accuracy_test  auc_train  auc_test   \n",
       "0              200        0.678044       0.675277   0.768813  0.704630  \\\n",
       "0              200        0.673432       0.682657   0.792484  0.743991   \n",
       "0              200        0.677122       0.673432   0.762806  0.702658   \n",
       "0              200        0.944649       0.671587   0.989190  0.709857   \n",
       "0              200        0.868081       0.688192   0.976227  0.716739   \n",
       "..             ...             ...            ...        ...       ...   \n",
       "0              200        1.000000       0.684502   1.000000  0.750130   \n",
       "0              200        1.000000       0.675277   1.000000  0.718329   \n",
       "0              200        1.000000       0.686347   1.000000  0.748313   \n",
       "0              200        1.000000       0.695572   1.000000  0.725656   \n",
       "0              200        1.000000       0.678967   1.000000  0.709449   \n",
       "\n",
       "    roc_auc_plot_test                                               path  \n",
       "0            0.704630  ML_CV_and_FINAL_RAW/10_CV_ML_Limma_CpGs/SVM_c_...  \n",
       "0            0.743991  ML_CV_and_FINAL_RAW/10_CV_ML_Limma_CpGs/SVM_c_...  \n",
       "0            0.702658  ML_CV_and_FINAL_RAW/10_CV_ML_Limma_CpGs/SVM_c_...  \n",
       "0            0.709857  ML_CV_and_FINAL_RAW/10_CV_ML_Limma_CpGs/SVM_c_...  \n",
       "0            0.716739  ML_CV_and_FINAL_RAW/10_CV_ML_Limma_CpGs/SVM_c_...  \n",
       "..                ...                                                ...  \n",
       "0            0.750130  ML_CV_and_FINAL_RAW/10_CV_ML_Limma_CpGs/Random...  \n",
       "0            0.718329  ML_CV_and_FINAL_RAW/10_CV_ML_Limma_CpGs/Random...  \n",
       "0            0.748313  ML_CV_and_FINAL_RAW/10_CV_ML_Limma_CpGs/Random...  \n",
       "0            0.725656  ML_CV_and_FINAL_RAW/10_CV_ML_Limma_CpGs/Random...  \n",
       "0            0.709449  ML_CV_and_FINAL_RAW/10_CV_ML_Limma_CpGs/Random...  \n",
       "\n",
       "[540 rows x 13 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas\n",
    "from HelperScriptsPY import helper_functions\n",
    "\n",
    "base_dir = \"ML_CV_and_FINAL_RAW/10_CV_ML_Limma_CpGs\"\n",
    "model_folders = [base_dir + \"/\" + x for x in os.listdir(base_dir)]\n",
    "\n",
    "performance_lists = []\n",
    "\n",
    "for model_folder in model_folders:\n",
    "    CV_folders = [model_folder + \"/\" + x for x in os.listdir(model_folder)]\n",
    "    target_folders = [path + \"/\" + x for path in CV_folders for x in os.listdir(path)]\n",
    "    analysis_files = [x + \"/\" + i for x in target_folders for i in os.listdir(x) if \"_model_performance.csv\" in i]\n",
    "\n",
    "    for path in analysis_files:\n",
    "        dataset = pandas.read_csv(path)\n",
    "        dataset[\"path\"] = path\n",
    "        performance_lists.append(dataset)\n",
    "performance_lists = pandas.concat(performance_lists)\n",
    "fold_data_ML = performance_lists\n",
    "fold_data_ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>epochs</th>\n",
       "      <th>fold</th>\n",
       "      <th>total_folds</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>mval</th>\n",
       "      <th>balance_alpha</th>\n",
       "      <th>cpg_type</th>\n",
       "      <th>limma_features</th>\n",
       "      <th>outer_cls_activ</th>\n",
       "      <th>...</th>\n",
       "      <th>kernel_regular</th>\n",
       "      <th>train_recon_loss</th>\n",
       "      <th>test_recon_loss</th>\n",
       "      <th>train_classification_loss</th>\n",
       "      <th>test_classification_loss</th>\n",
       "      <th>accuracy_train</th>\n",
       "      <th>accuracy_test</th>\n",
       "      <th>auc_train</th>\n",
       "      <th>auc_test</th>\n",
       "      <th>roc_auc_plot_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>innerDNNClassifier</td>\n",
       "      <td>2000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>0.1</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>...</td>\n",
       "      <td>l1_l2</td>\n",
       "      <td>0.143370</td>\n",
       "      <td>0.149693</td>\n",
       "      <td>0.145612</td>\n",
       "      <td>1.263702</td>\n",
       "      <td>0.964945</td>\n",
       "      <td>0.642066</td>\n",
       "      <td>0.972801</td>\n",
       "      <td>0.616044</td>\n",
       "      <td>0.616044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>innerDNNClassifier</td>\n",
       "      <td>2000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>0.1</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>...</td>\n",
       "      <td>l1_l2</td>\n",
       "      <td>0.146925</td>\n",
       "      <td>0.158182</td>\n",
       "      <td>0.149830</td>\n",
       "      <td>1.274926</td>\n",
       "      <td>0.964022</td>\n",
       "      <td>0.618081</td>\n",
       "      <td>0.967351</td>\n",
       "      <td>0.634399</td>\n",
       "      <td>0.634399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>innerDNNClassifier</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>0.1</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>...</td>\n",
       "      <td>l1_l2</td>\n",
       "      <td>0.155649</td>\n",
       "      <td>0.160575</td>\n",
       "      <td>0.446147</td>\n",
       "      <td>0.695603</td>\n",
       "      <td>0.814576</td>\n",
       "      <td>0.695572</td>\n",
       "      <td>0.832440</td>\n",
       "      <td>0.643694</td>\n",
       "      <td>0.643694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>innerDNNClassifier</td>\n",
       "      <td>2000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>0.1</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>...</td>\n",
       "      <td>l1_l2</td>\n",
       "      <td>0.151942</td>\n",
       "      <td>0.145746</td>\n",
       "      <td>0.505819</td>\n",
       "      <td>0.652897</td>\n",
       "      <td>0.718635</td>\n",
       "      <td>0.662362</td>\n",
       "      <td>0.772157</td>\n",
       "      <td>0.639553</td>\n",
       "      <td>0.639553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>innerDNNClassifier</td>\n",
       "      <td>2000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>0.1</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>...</td>\n",
       "      <td>l1_l2</td>\n",
       "      <td>0.155780</td>\n",
       "      <td>0.183126</td>\n",
       "      <td>0.294463</td>\n",
       "      <td>0.873269</td>\n",
       "      <td>0.851476</td>\n",
       "      <td>0.664207</td>\n",
       "      <td>0.924937</td>\n",
       "      <td>0.695052</td>\n",
       "      <td>0.695052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>innerDNNClassifier</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>0.1</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>...</td>\n",
       "      <td>l1_l2</td>\n",
       "      <td>0.181142</td>\n",
       "      <td>0.173052</td>\n",
       "      <td>0.258784</td>\n",
       "      <td>0.991981</td>\n",
       "      <td>0.910517</td>\n",
       "      <td>0.638376</td>\n",
       "      <td>0.936593</td>\n",
       "      <td>0.659940</td>\n",
       "      <td>0.659940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>innerDNNClassifier</td>\n",
       "      <td>2000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>0.1</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>...</td>\n",
       "      <td>l1_l2</td>\n",
       "      <td>0.195924</td>\n",
       "      <td>0.199112</td>\n",
       "      <td>0.269310</td>\n",
       "      <td>1.110848</td>\n",
       "      <td>0.843173</td>\n",
       "      <td>0.610701</td>\n",
       "      <td>0.943860</td>\n",
       "      <td>0.652328</td>\n",
       "      <td>0.652328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>innerDNNClassifier</td>\n",
       "      <td>2000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>0.1</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>...</td>\n",
       "      <td>l1_l2</td>\n",
       "      <td>0.146457</td>\n",
       "      <td>0.151758</td>\n",
       "      <td>0.140817</td>\n",
       "      <td>1.298126</td>\n",
       "      <td>0.971402</td>\n",
       "      <td>0.618081</td>\n",
       "      <td>0.956065</td>\n",
       "      <td>0.656178</td>\n",
       "      <td>0.656178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>innerDNNClassifier</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>0.1</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>...</td>\n",
       "      <td>l1_l2</td>\n",
       "      <td>0.178517</td>\n",
       "      <td>0.188245</td>\n",
       "      <td>0.285102</td>\n",
       "      <td>0.873879</td>\n",
       "      <td>0.842251</td>\n",
       "      <td>0.627306</td>\n",
       "      <td>0.933809</td>\n",
       "      <td>0.659369</td>\n",
       "      <td>0.659369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>innerDNNClassifier</td>\n",
       "      <td>2000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>0.1</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>...</td>\n",
       "      <td>l1_l2</td>\n",
       "      <td>0.138471</td>\n",
       "      <td>0.140341</td>\n",
       "      <td>0.456420</td>\n",
       "      <td>0.619707</td>\n",
       "      <td>0.812731</td>\n",
       "      <td>0.708487</td>\n",
       "      <td>0.808513</td>\n",
       "      <td>0.635570</td>\n",
       "      <td>0.635570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>innerDNNClassifier</td>\n",
       "      <td>2000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>0.1</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>...</td>\n",
       "      <td>l1_l2</td>\n",
       "      <td>0.136482</td>\n",
       "      <td>0.140799</td>\n",
       "      <td>0.172776</td>\n",
       "      <td>1.223675</td>\n",
       "      <td>0.949262</td>\n",
       "      <td>0.632841</td>\n",
       "      <td>0.950483</td>\n",
       "      <td>0.654207</td>\n",
       "      <td>0.654207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>innerDNNClassifier</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>0.1</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>...</td>\n",
       "      <td>l1_l2</td>\n",
       "      <td>0.192140</td>\n",
       "      <td>0.233567</td>\n",
       "      <td>0.302972</td>\n",
       "      <td>0.983541</td>\n",
       "      <td>0.859779</td>\n",
       "      <td>0.612546</td>\n",
       "      <td>0.914951</td>\n",
       "      <td>0.638813</td>\n",
       "      <td>0.638813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>innerDNNClassifier</td>\n",
       "      <td>2000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>0.1</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>...</td>\n",
       "      <td>l1_l2</td>\n",
       "      <td>0.229096</td>\n",
       "      <td>0.233732</td>\n",
       "      <td>0.277311</td>\n",
       "      <td>1.019154</td>\n",
       "      <td>0.849631</td>\n",
       "      <td>0.590406</td>\n",
       "      <td>0.931189</td>\n",
       "      <td>0.647705</td>\n",
       "      <td>0.647705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>innerDNNClassifier</td>\n",
       "      <td>2000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>0.1</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>...</td>\n",
       "      <td>l1_l2</td>\n",
       "      <td>0.115287</td>\n",
       "      <td>0.117661</td>\n",
       "      <td>0.474919</td>\n",
       "      <td>0.730196</td>\n",
       "      <td>0.793358</td>\n",
       "      <td>0.662362</td>\n",
       "      <td>0.750408</td>\n",
       "      <td>0.578187</td>\n",
       "      <td>0.578187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>innerDNNClassifier</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>0.1</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>...</td>\n",
       "      <td>l1_l2</td>\n",
       "      <td>0.148218</td>\n",
       "      <td>0.172581</td>\n",
       "      <td>0.130754</td>\n",
       "      <td>1.345867</td>\n",
       "      <td>0.971402</td>\n",
       "      <td>0.619926</td>\n",
       "      <td>0.960092</td>\n",
       "      <td>0.642035</td>\n",
       "      <td>0.642035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>innerDNNClassifier</td>\n",
       "      <td>2000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>0.1</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>...</td>\n",
       "      <td>l1_l2</td>\n",
       "      <td>0.132594</td>\n",
       "      <td>0.136515</td>\n",
       "      <td>0.488142</td>\n",
       "      <td>0.638304</td>\n",
       "      <td>0.749077</td>\n",
       "      <td>0.699262</td>\n",
       "      <td>0.785983</td>\n",
       "      <td>0.696099</td>\n",
       "      <td>0.696099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>innerDNNClassifier</td>\n",
       "      <td>2000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>0.1</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>...</td>\n",
       "      <td>l1_l2</td>\n",
       "      <td>0.173817</td>\n",
       "      <td>0.180668</td>\n",
       "      <td>0.362580</td>\n",
       "      <td>0.749131</td>\n",
       "      <td>0.852399</td>\n",
       "      <td>0.638376</td>\n",
       "      <td>0.908048</td>\n",
       "      <td>0.683180</td>\n",
       "      <td>0.683180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>innerDNNClassifier</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>0.1</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>...</td>\n",
       "      <td>l1_l2</td>\n",
       "      <td>0.195355</td>\n",
       "      <td>0.205269</td>\n",
       "      <td>0.273726</td>\n",
       "      <td>0.821227</td>\n",
       "      <td>0.908672</td>\n",
       "      <td>0.666052</td>\n",
       "      <td>0.941961</td>\n",
       "      <td>0.690027</td>\n",
       "      <td>0.690027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>innerDNNClassifier</td>\n",
       "      <td>2000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>0.1</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>...</td>\n",
       "      <td>l1_l2</td>\n",
       "      <td>0.194027</td>\n",
       "      <td>0.187471</td>\n",
       "      <td>0.275903</td>\n",
       "      <td>0.920119</td>\n",
       "      <td>0.906827</td>\n",
       "      <td>0.638376</td>\n",
       "      <td>0.939426</td>\n",
       "      <td>0.642408</td>\n",
       "      <td>0.642408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>innerDNNClassifier</td>\n",
       "      <td>2000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>0.1</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>...</td>\n",
       "      <td>l1_l2</td>\n",
       "      <td>0.140555</td>\n",
       "      <td>0.137897</td>\n",
       "      <td>0.298853</td>\n",
       "      <td>0.851712</td>\n",
       "      <td>0.896679</td>\n",
       "      <td>0.666052</td>\n",
       "      <td>0.938055</td>\n",
       "      <td>0.651055</td>\n",
       "      <td>0.651055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>innerDNNClassifier</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>0.1</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>...</td>\n",
       "      <td>l1_l2</td>\n",
       "      <td>0.218010</td>\n",
       "      <td>0.229179</td>\n",
       "      <td>0.289720</td>\n",
       "      <td>0.912680</td>\n",
       "      <td>0.878229</td>\n",
       "      <td>0.632841</td>\n",
       "      <td>0.949296</td>\n",
       "      <td>0.639870</td>\n",
       "      <td>0.639870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>innerDNNClassifier</td>\n",
       "      <td>2000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>0.1</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>...</td>\n",
       "      <td>l1_l2</td>\n",
       "      <td>0.202827</td>\n",
       "      <td>0.222106</td>\n",
       "      <td>0.126389</td>\n",
       "      <td>1.426592</td>\n",
       "      <td>0.970480</td>\n",
       "      <td>0.642066</td>\n",
       "      <td>0.959908</td>\n",
       "      <td>0.673173</td>\n",
       "      <td>0.673173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>innerDNNClassifier</td>\n",
       "      <td>2000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>0.1</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>...</td>\n",
       "      <td>l1_l2</td>\n",
       "      <td>0.131256</td>\n",
       "      <td>0.132979</td>\n",
       "      <td>0.483950</td>\n",
       "      <td>0.603859</td>\n",
       "      <td>0.783210</td>\n",
       "      <td>0.719557</td>\n",
       "      <td>0.776902</td>\n",
       "      <td>0.710100</td>\n",
       "      <td>0.710100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>innerDNNClassifier</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>0.1</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>...</td>\n",
       "      <td>l1_l2</td>\n",
       "      <td>0.141681</td>\n",
       "      <td>0.158811</td>\n",
       "      <td>0.377005</td>\n",
       "      <td>0.875221</td>\n",
       "      <td>0.842251</td>\n",
       "      <td>0.645756</td>\n",
       "      <td>0.872421</td>\n",
       "      <td>0.662649</td>\n",
       "      <td>0.662649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>innerDNNClassifier</td>\n",
       "      <td>2000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>0.1</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>...</td>\n",
       "      <td>l1_l2</td>\n",
       "      <td>0.123330</td>\n",
       "      <td>0.129918</td>\n",
       "      <td>0.465579</td>\n",
       "      <td>0.704501</td>\n",
       "      <td>0.798893</td>\n",
       "      <td>0.666052</td>\n",
       "      <td>0.840001</td>\n",
       "      <td>0.646583</td>\n",
       "      <td>0.646583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>innerDNNClassifier</td>\n",
       "      <td>2000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>0.1</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>...</td>\n",
       "      <td>l1_l2</td>\n",
       "      <td>0.168336</td>\n",
       "      <td>0.175502</td>\n",
       "      <td>0.235548</td>\n",
       "      <td>1.171634</td>\n",
       "      <td>0.877306</td>\n",
       "      <td>0.621771</td>\n",
       "      <td>0.942562</td>\n",
       "      <td>0.646090</td>\n",
       "      <td>0.646090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>innerDNNClassifier</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>0.1</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>...</td>\n",
       "      <td>l1_l2</td>\n",
       "      <td>0.200013</td>\n",
       "      <td>0.194734</td>\n",
       "      <td>0.276121</td>\n",
       "      <td>0.907658</td>\n",
       "      <td>0.902214</td>\n",
       "      <td>0.658672</td>\n",
       "      <td>0.940329</td>\n",
       "      <td>0.655705</td>\n",
       "      <td>0.655705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>innerDNNClassifier</td>\n",
       "      <td>2000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>0.1</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>...</td>\n",
       "      <td>l1_l2</td>\n",
       "      <td>0.191632</td>\n",
       "      <td>0.193188</td>\n",
       "      <td>0.259147</td>\n",
       "      <td>0.907995</td>\n",
       "      <td>0.880074</td>\n",
       "      <td>0.645756</td>\n",
       "      <td>0.937064</td>\n",
       "      <td>0.685100</td>\n",
       "      <td>0.685100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>innerDNNClassifier</td>\n",
       "      <td>2000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>0.1</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>...</td>\n",
       "      <td>l1_l2</td>\n",
       "      <td>0.167765</td>\n",
       "      <td>0.171926</td>\n",
       "      <td>0.269536</td>\n",
       "      <td>1.040157</td>\n",
       "      <td>0.870849</td>\n",
       "      <td>0.621771</td>\n",
       "      <td>0.935148</td>\n",
       "      <td>0.639242</td>\n",
       "      <td>0.639242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>innerDNNClassifier</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>0.1</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>...</td>\n",
       "      <td>l1_l2</td>\n",
       "      <td>0.172992</td>\n",
       "      <td>0.214221</td>\n",
       "      <td>0.116607</td>\n",
       "      <td>1.298156</td>\n",
       "      <td>0.976015</td>\n",
       "      <td>0.634686</td>\n",
       "      <td>0.955076</td>\n",
       "      <td>0.667914</td>\n",
       "      <td>0.667914</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                model  epochs  fold  total_folds  batch_size  mval   \n",
       "0  innerDNNClassifier    2000     3            3         128  Mval  \\\n",
       "0  innerDNNClassifier    2000     2            3         128  Mval   \n",
       "0  innerDNNClassifier    2000     1            3         128  Mval   \n",
       "0  innerDNNClassifier    2000     3            3         128  Mval   \n",
       "0  innerDNNClassifier    2000     2            3         128  Mval   \n",
       "0  innerDNNClassifier    2000     1            3         128  Mval   \n",
       "0  innerDNNClassifier    2000     3            3         128  Mval   \n",
       "0  innerDNNClassifier    2000     2            3         128  Mval   \n",
       "0  innerDNNClassifier    2000     1            3         128  Mval   \n",
       "0  innerDNNClassifier    2000     3            3         128  Mval   \n",
       "0  innerDNNClassifier    2000     2            3         128  Mval   \n",
       "0  innerDNNClassifier    2000     1            3         128  Mval   \n",
       "0  innerDNNClassifier    2000     3            3         128  Mval   \n",
       "0  innerDNNClassifier    2000     2            3         128  Mval   \n",
       "0  innerDNNClassifier    2000     1            3         128  Mval   \n",
       "0  innerDNNClassifier    2000     3            3         128  Mval   \n",
       "0  innerDNNClassifier    2000     2            3         128  Mval   \n",
       "0  innerDNNClassifier    2000     1            3         128  Mval   \n",
       "0  innerDNNClassifier    2000     3            3         128  Mval   \n",
       "0  innerDNNClassifier    2000     2            3         128  Mval   \n",
       "0  innerDNNClassifier    2000     1            3         128  Mval   \n",
       "0  innerDNNClassifier    2000     3            3         128  Mval   \n",
       "0  innerDNNClassifier    2000     2            3         128  Mval   \n",
       "0  innerDNNClassifier    2000     1            3         128  Mval   \n",
       "0  innerDNNClassifier    2000     3            3         128  Mval   \n",
       "0  innerDNNClassifier    2000     2            3         128  Mval   \n",
       "0  innerDNNClassifier    2000     1            3         128  Mval   \n",
       "0  innerDNNClassifier    2000     3            3         128  Mval   \n",
       "0  innerDNNClassifier    2000     2            3         128  Mval   \n",
       "0  innerDNNClassifier    2000     1            3         128  Mval   \n",
       "\n",
       "   balance_alpha cpg_type  limma_features outer_cls_activ  ... kernel_regular   \n",
       "0            0.1      ALL             200         sigmoid  ...          l1_l2  \\\n",
       "0            0.1      ALL             200         sigmoid  ...          l1_l2   \n",
       "0            0.1      ALL             200         sigmoid  ...          l1_l2   \n",
       "0            0.1      ALL             200         sigmoid  ...          l1_l2   \n",
       "0            0.1      ALL             200         sigmoid  ...          l1_l2   \n",
       "0            0.1      ALL             200         sigmoid  ...          l1_l2   \n",
       "0            0.1      ALL             200         sigmoid  ...          l1_l2   \n",
       "0            0.1      ALL             200         sigmoid  ...          l1_l2   \n",
       "0            0.1      ALL             200         sigmoid  ...          l1_l2   \n",
       "0            0.1      ALL             200         sigmoid  ...          l1_l2   \n",
       "0            0.1      ALL             200         sigmoid  ...          l1_l2   \n",
       "0            0.1      ALL             200         sigmoid  ...          l1_l2   \n",
       "0            0.1      ALL             200         sigmoid  ...          l1_l2   \n",
       "0            0.1      ALL             200         sigmoid  ...          l1_l2   \n",
       "0            0.1      ALL             200         sigmoid  ...          l1_l2   \n",
       "0            0.1      ALL             200         sigmoid  ...          l1_l2   \n",
       "0            0.1      ALL             200         sigmoid  ...          l1_l2   \n",
       "0            0.1      ALL             200         sigmoid  ...          l1_l2   \n",
       "0            0.1      ALL             200         sigmoid  ...          l1_l2   \n",
       "0            0.1      ALL             200         sigmoid  ...          l1_l2   \n",
       "0            0.1      ALL             200         sigmoid  ...          l1_l2   \n",
       "0            0.1      ALL             200         sigmoid  ...          l1_l2   \n",
       "0            0.1      ALL             200         sigmoid  ...          l1_l2   \n",
       "0            0.1      ALL             200         sigmoid  ...          l1_l2   \n",
       "0            0.1      ALL             200         sigmoid  ...          l1_l2   \n",
       "0            0.1      ALL             200         sigmoid  ...          l1_l2   \n",
       "0            0.1      ALL             200         sigmoid  ...          l1_l2   \n",
       "0            0.1      ALL             200         sigmoid  ...          l1_l2   \n",
       "0            0.1      ALL             200         sigmoid  ...          l1_l2   \n",
       "0            0.1      ALL             200         sigmoid  ...          l1_l2   \n",
       "\n",
       "  train_recon_loss  test_recon_loss  train_classification_loss   \n",
       "0         0.143370         0.149693                   0.145612  \\\n",
       "0         0.146925         0.158182                   0.149830   \n",
       "0         0.155649         0.160575                   0.446147   \n",
       "0         0.151942         0.145746                   0.505819   \n",
       "0         0.155780         0.183126                   0.294463   \n",
       "0         0.181142         0.173052                   0.258784   \n",
       "0         0.195924         0.199112                   0.269310   \n",
       "0         0.146457         0.151758                   0.140817   \n",
       "0         0.178517         0.188245                   0.285102   \n",
       "0         0.138471         0.140341                   0.456420   \n",
       "0         0.136482         0.140799                   0.172776   \n",
       "0         0.192140         0.233567                   0.302972   \n",
       "0         0.229096         0.233732                   0.277311   \n",
       "0         0.115287         0.117661                   0.474919   \n",
       "0         0.148218         0.172581                   0.130754   \n",
       "0         0.132594         0.136515                   0.488142   \n",
       "0         0.173817         0.180668                   0.362580   \n",
       "0         0.195355         0.205269                   0.273726   \n",
       "0         0.194027         0.187471                   0.275903   \n",
       "0         0.140555         0.137897                   0.298853   \n",
       "0         0.218010         0.229179                   0.289720   \n",
       "0         0.202827         0.222106                   0.126389   \n",
       "0         0.131256         0.132979                   0.483950   \n",
       "0         0.141681         0.158811                   0.377005   \n",
       "0         0.123330         0.129918                   0.465579   \n",
       "0         0.168336         0.175502                   0.235548   \n",
       "0         0.200013         0.194734                   0.276121   \n",
       "0         0.191632         0.193188                   0.259147   \n",
       "0         0.167765         0.171926                   0.269536   \n",
       "0         0.172992         0.214221                   0.116607   \n",
       "\n",
       "  test_classification_loss accuracy_train accuracy_test auc_train  auc_test   \n",
       "0                 1.263702       0.964945      0.642066  0.972801  0.616044  \\\n",
       "0                 1.274926       0.964022      0.618081  0.967351  0.634399   \n",
       "0                 0.695603       0.814576      0.695572  0.832440  0.643694   \n",
       "0                 0.652897       0.718635      0.662362  0.772157  0.639553   \n",
       "0                 0.873269       0.851476      0.664207  0.924937  0.695052   \n",
       "0                 0.991981       0.910517      0.638376  0.936593  0.659940   \n",
       "0                 1.110848       0.843173      0.610701  0.943860  0.652328   \n",
       "0                 1.298126       0.971402      0.618081  0.956065  0.656178   \n",
       "0                 0.873879       0.842251      0.627306  0.933809  0.659369   \n",
       "0                 0.619707       0.812731      0.708487  0.808513  0.635570   \n",
       "0                 1.223675       0.949262      0.632841  0.950483  0.654207   \n",
       "0                 0.983541       0.859779      0.612546  0.914951  0.638813   \n",
       "0                 1.019154       0.849631      0.590406  0.931189  0.647705   \n",
       "0                 0.730196       0.793358      0.662362  0.750408  0.578187   \n",
       "0                 1.345867       0.971402      0.619926  0.960092  0.642035   \n",
       "0                 0.638304       0.749077      0.699262  0.785983  0.696099   \n",
       "0                 0.749131       0.852399      0.638376  0.908048  0.683180   \n",
       "0                 0.821227       0.908672      0.666052  0.941961  0.690027   \n",
       "0                 0.920119       0.906827      0.638376  0.939426  0.642408   \n",
       "0                 0.851712       0.896679      0.666052  0.938055  0.651055   \n",
       "0                 0.912680       0.878229      0.632841  0.949296  0.639870   \n",
       "0                 1.426592       0.970480      0.642066  0.959908  0.673173   \n",
       "0                 0.603859       0.783210      0.719557  0.776902  0.710100   \n",
       "0                 0.875221       0.842251      0.645756  0.872421  0.662649   \n",
       "0                 0.704501       0.798893      0.666052  0.840001  0.646583   \n",
       "0                 1.171634       0.877306      0.621771  0.942562  0.646090   \n",
       "0                 0.907658       0.902214      0.658672  0.940329  0.655705   \n",
       "0                 0.907995       0.880074      0.645756  0.937064  0.685100   \n",
       "0                 1.040157       0.870849      0.621771  0.935148  0.639242   \n",
       "0                 1.298156       0.976015      0.634686  0.955076  0.667914   \n",
       "\n",
       "   roc_auc_plot_test  \n",
       "0           0.616044  \n",
       "0           0.634399  \n",
       "0           0.643694  \n",
       "0           0.639553  \n",
       "0           0.695052  \n",
       "0           0.659940  \n",
       "0           0.652328  \n",
       "0           0.656178  \n",
       "0           0.659369  \n",
       "0           0.635570  \n",
       "0           0.654207  \n",
       "0           0.638813  \n",
       "0           0.647705  \n",
       "0           0.578187  \n",
       "0           0.642035  \n",
       "0           0.696099  \n",
       "0           0.683180  \n",
       "0           0.690027  \n",
       "0           0.642408  \n",
       "0           0.651055  \n",
       "0           0.639870  \n",
       "0           0.673173  \n",
       "0           0.710100  \n",
       "0           0.662649  \n",
       "0           0.646583  \n",
       "0           0.646090  \n",
       "0           0.655705  \n",
       "0           0.685100  \n",
       "0           0.639242  \n",
       "0           0.667914  \n",
       "\n",
       "[30 rows x 27 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas\n",
    "from HelperScriptsPY import helper_functions\n",
    "\n",
    "base_dir = \"10CV_DNN_RAW/10_CV_JointAE\"\n",
    "CV_folders = [base_dir + \"/\" + x for x in os.listdir(base_dir) if os.path.isdir(base_dir + \"/\" + x)]\n",
    "target_folders = [path + \"/\" + x for path in CV_folders for x in os.listdir(path)]\n",
    "analysis_files = [x + \"/\" + i for x in target_folders for i in os.listdir(x) if \"_model_performance.csv\" in i]\n",
    "performance_lists = []\n",
    "\n",
    "for x in analysis_files:\n",
    "    dataset = pandas.read_csv(x)\n",
    "    dataset = helper_functions.drop_useless_column(dataset)\n",
    "    performance_lists.append(dataset)\n",
    "\n",
    "performance_df = pandas.concat(performance_lists)\n",
    "fold_data_JAE = performance_df\n",
    "fold_data_JAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>epochs</th>\n",
       "      <th>fold</th>\n",
       "      <th>total_folds</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>mval</th>\n",
       "      <th>balance_alpha</th>\n",
       "      <th>cpg_type</th>\n",
       "      <th>limma_features</th>\n",
       "      <th>outer_cls_activ</th>\n",
       "      <th>...</th>\n",
       "      <th>test_recon_loss</th>\n",
       "      <th>train_classification_loss</th>\n",
       "      <th>test_classification_loss</th>\n",
       "      <th>train_kl_loss</th>\n",
       "      <th>test_kl_loss</th>\n",
       "      <th>accuracy_train</th>\n",
       "      <th>accuracy_test</th>\n",
       "      <th>auc_train</th>\n",
       "      <th>auc_test</th>\n",
       "      <th>roc_auc_plot_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>innerDNNClassifier</td>\n",
       "      <td>2250</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>tanh</td>\n",
       "      <td>...</td>\n",
       "      <td>0.155804</td>\n",
       "      <td>0.089293</td>\n",
       "      <td>1.519166</td>\n",
       "      <td>0.129897</td>\n",
       "      <td>0.128450</td>\n",
       "      <td>0.977860</td>\n",
       "      <td>0.603321</td>\n",
       "      <td>0.968487</td>\n",
       "      <td>0.633277</td>\n",
       "      <td>0.633277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>innerDNNClassifier</td>\n",
       "      <td>2250</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>tanh</td>\n",
       "      <td>...</td>\n",
       "      <td>0.163464</td>\n",
       "      <td>0.057235</td>\n",
       "      <td>1.410656</td>\n",
       "      <td>0.121917</td>\n",
       "      <td>0.121305</td>\n",
       "      <td>0.984317</td>\n",
       "      <td>0.627306</td>\n",
       "      <td>0.980422</td>\n",
       "      <td>0.657234</td>\n",
       "      <td>0.657234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>innerDNNClassifier</td>\n",
       "      <td>2250</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>tanh</td>\n",
       "      <td>...</td>\n",
       "      <td>0.143579</td>\n",
       "      <td>0.070557</td>\n",
       "      <td>1.458056</td>\n",
       "      <td>0.143317</td>\n",
       "      <td>0.142967</td>\n",
       "      <td>0.980627</td>\n",
       "      <td>0.605166</td>\n",
       "      <td>0.980181</td>\n",
       "      <td>0.624970</td>\n",
       "      <td>0.624970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>innerDNNClassifier</td>\n",
       "      <td>2250</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>tanh</td>\n",
       "      <td>...</td>\n",
       "      <td>0.159659</td>\n",
       "      <td>0.085215</td>\n",
       "      <td>1.449935</td>\n",
       "      <td>0.123379</td>\n",
       "      <td>0.124970</td>\n",
       "      <td>0.976937</td>\n",
       "      <td>0.612546</td>\n",
       "      <td>0.966059</td>\n",
       "      <td>0.662018</td>\n",
       "      <td>0.662018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>innerDNNClassifier</td>\n",
       "      <td>2250</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>tanh</td>\n",
       "      <td>...</td>\n",
       "      <td>0.162721</td>\n",
       "      <td>0.081335</td>\n",
       "      <td>1.334476</td>\n",
       "      <td>0.130138</td>\n",
       "      <td>0.130285</td>\n",
       "      <td>0.977860</td>\n",
       "      <td>0.645756</td>\n",
       "      <td>0.974470</td>\n",
       "      <td>0.646411</td>\n",
       "      <td>0.646411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>innerDNNClassifier</td>\n",
       "      <td>2250</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>tanh</td>\n",
       "      <td>...</td>\n",
       "      <td>0.147903</td>\n",
       "      <td>0.071018</td>\n",
       "      <td>1.444149</td>\n",
       "      <td>0.122690</td>\n",
       "      <td>0.122498</td>\n",
       "      <td>0.982472</td>\n",
       "      <td>0.619926</td>\n",
       "      <td>0.968084</td>\n",
       "      <td>0.630700</td>\n",
       "      <td>0.630700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>innerDNNClassifier</td>\n",
       "      <td>2250</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>tanh</td>\n",
       "      <td>...</td>\n",
       "      <td>0.183957</td>\n",
       "      <td>0.090087</td>\n",
       "      <td>1.308106</td>\n",
       "      <td>0.142313</td>\n",
       "      <td>0.138134</td>\n",
       "      <td>0.975092</td>\n",
       "      <td>0.654982</td>\n",
       "      <td>0.978033</td>\n",
       "      <td>0.649123</td>\n",
       "      <td>0.649123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>innerDNNClassifier</td>\n",
       "      <td>2250</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>tanh</td>\n",
       "      <td>...</td>\n",
       "      <td>0.210761</td>\n",
       "      <td>0.063667</td>\n",
       "      <td>1.427684</td>\n",
       "      <td>0.121391</td>\n",
       "      <td>0.120084</td>\n",
       "      <td>0.983395</td>\n",
       "      <td>0.627306</td>\n",
       "      <td>0.979657</td>\n",
       "      <td>0.632062</td>\n",
       "      <td>0.632062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>innerDNNClassifier</td>\n",
       "      <td>2250</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>tanh</td>\n",
       "      <td>...</td>\n",
       "      <td>0.145002</td>\n",
       "      <td>0.106360</td>\n",
       "      <td>1.379983</td>\n",
       "      <td>0.120226</td>\n",
       "      <td>0.119935</td>\n",
       "      <td>0.974170</td>\n",
       "      <td>0.634686</td>\n",
       "      <td>0.960303</td>\n",
       "      <td>0.666297</td>\n",
       "      <td>0.666297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>innerDNNClassifier</td>\n",
       "      <td>2250</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>tanh</td>\n",
       "      <td>...</td>\n",
       "      <td>0.156162</td>\n",
       "      <td>0.072917</td>\n",
       "      <td>1.476897</td>\n",
       "      <td>0.142006</td>\n",
       "      <td>0.142912</td>\n",
       "      <td>0.980627</td>\n",
       "      <td>0.605166</td>\n",
       "      <td>0.973355</td>\n",
       "      <td>0.655555</td>\n",
       "      <td>0.655555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>innerDNNClassifier</td>\n",
       "      <td>2250</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>tanh</td>\n",
       "      <td>...</td>\n",
       "      <td>0.150495</td>\n",
       "      <td>0.087918</td>\n",
       "      <td>1.476599</td>\n",
       "      <td>0.130808</td>\n",
       "      <td>0.130011</td>\n",
       "      <td>0.973247</td>\n",
       "      <td>0.605166</td>\n",
       "      <td>0.970548</td>\n",
       "      <td>0.652927</td>\n",
       "      <td>0.652927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>innerDNNClassifier</td>\n",
       "      <td>2250</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>tanh</td>\n",
       "      <td>...</td>\n",
       "      <td>0.206883</td>\n",
       "      <td>0.066324</td>\n",
       "      <td>1.396795</td>\n",
       "      <td>0.119825</td>\n",
       "      <td>0.118426</td>\n",
       "      <td>0.982472</td>\n",
       "      <td>0.630996</td>\n",
       "      <td>0.976693</td>\n",
       "      <td>0.665093</td>\n",
       "      <td>0.665093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>innerDNNClassifier</td>\n",
       "      <td>2250</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>tanh</td>\n",
       "      <td>...</td>\n",
       "      <td>0.165727</td>\n",
       "      <td>0.056766</td>\n",
       "      <td>1.312577</td>\n",
       "      <td>0.118049</td>\n",
       "      <td>0.117575</td>\n",
       "      <td>0.984317</td>\n",
       "      <td>0.658672</td>\n",
       "      <td>0.980111</td>\n",
       "      <td>0.662556</td>\n",
       "      <td>0.662556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>innerDNNClassifier</td>\n",
       "      <td>2250</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>tanh</td>\n",
       "      <td>...</td>\n",
       "      <td>0.181448</td>\n",
       "      <td>0.078988</td>\n",
       "      <td>1.369049</td>\n",
       "      <td>0.126943</td>\n",
       "      <td>0.126882</td>\n",
       "      <td>0.978782</td>\n",
       "      <td>0.634686</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.677497</td>\n",
       "      <td>0.677497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>innerDNNClassifier</td>\n",
       "      <td>2250</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>tanh</td>\n",
       "      <td>...</td>\n",
       "      <td>0.150045</td>\n",
       "      <td>0.084277</td>\n",
       "      <td>1.357063</td>\n",
       "      <td>0.122666</td>\n",
       "      <td>0.122194</td>\n",
       "      <td>0.978782</td>\n",
       "      <td>0.645756</td>\n",
       "      <td>0.969592</td>\n",
       "      <td>0.648608</td>\n",
       "      <td>0.648608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>innerDNNClassifier</td>\n",
       "      <td>2250</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>tanh</td>\n",
       "      <td>...</td>\n",
       "      <td>0.144743</td>\n",
       "      <td>0.072663</td>\n",
       "      <td>1.441956</td>\n",
       "      <td>0.143873</td>\n",
       "      <td>0.140224</td>\n",
       "      <td>0.979705</td>\n",
       "      <td>0.616236</td>\n",
       "      <td>0.988356</td>\n",
       "      <td>0.611516</td>\n",
       "      <td>0.611516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>innerDNNClassifier</td>\n",
       "      <td>2250</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>tanh</td>\n",
       "      <td>...</td>\n",
       "      <td>0.161723</td>\n",
       "      <td>0.080719</td>\n",
       "      <td>1.339395</td>\n",
       "      <td>0.135920</td>\n",
       "      <td>0.139419</td>\n",
       "      <td>0.978782</td>\n",
       "      <td>0.640221</td>\n",
       "      <td>0.969168</td>\n",
       "      <td>0.659267</td>\n",
       "      <td>0.659267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>innerDNNClassifier</td>\n",
       "      <td>2250</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>tanh</td>\n",
       "      <td>...</td>\n",
       "      <td>0.208393</td>\n",
       "      <td>0.035559</td>\n",
       "      <td>1.377769</td>\n",
       "      <td>0.126739</td>\n",
       "      <td>0.123418</td>\n",
       "      <td>0.990775</td>\n",
       "      <td>0.632841</td>\n",
       "      <td>0.986591</td>\n",
       "      <td>0.640987</td>\n",
       "      <td>0.640987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>innerDNNClassifier</td>\n",
       "      <td>2250</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>tanh</td>\n",
       "      <td>...</td>\n",
       "      <td>0.158443</td>\n",
       "      <td>0.075046</td>\n",
       "      <td>1.442824</td>\n",
       "      <td>0.125091</td>\n",
       "      <td>0.127466</td>\n",
       "      <td>0.980627</td>\n",
       "      <td>0.621771</td>\n",
       "      <td>0.975669</td>\n",
       "      <td>0.649455</td>\n",
       "      <td>0.649455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>innerDNNClassifier</td>\n",
       "      <td>2250</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>tanh</td>\n",
       "      <td>...</td>\n",
       "      <td>0.170046</td>\n",
       "      <td>0.092065</td>\n",
       "      <td>1.434818</td>\n",
       "      <td>0.143504</td>\n",
       "      <td>0.138440</td>\n",
       "      <td>0.975092</td>\n",
       "      <td>0.618081</td>\n",
       "      <td>0.968097</td>\n",
       "      <td>0.647211</td>\n",
       "      <td>0.647211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>innerDNNClassifier</td>\n",
       "      <td>2250</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>tanh</td>\n",
       "      <td>...</td>\n",
       "      <td>0.153185</td>\n",
       "      <td>0.061641</td>\n",
       "      <td>1.419275</td>\n",
       "      <td>0.130429</td>\n",
       "      <td>0.126978</td>\n",
       "      <td>0.985240</td>\n",
       "      <td>0.618081</td>\n",
       "      <td>0.979848</td>\n",
       "      <td>0.624843</td>\n",
       "      <td>0.624843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>innerDNNClassifier</td>\n",
       "      <td>2250</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>tanh</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166323</td>\n",
       "      <td>0.136908</td>\n",
       "      <td>1.432840</td>\n",
       "      <td>0.123352</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>0.957565</td>\n",
       "      <td>0.614391</td>\n",
       "      <td>0.975055</td>\n",
       "      <td>0.671840</td>\n",
       "      <td>0.671840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>innerDNNClassifier</td>\n",
       "      <td>2250</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>tanh</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132295</td>\n",
       "      <td>0.063783</td>\n",
       "      <td>1.430563</td>\n",
       "      <td>0.135125</td>\n",
       "      <td>0.136299</td>\n",
       "      <td>0.983395</td>\n",
       "      <td>0.619926</td>\n",
       "      <td>0.977330</td>\n",
       "      <td>0.641892</td>\n",
       "      <td>0.641892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>innerDNNClassifier</td>\n",
       "      <td>2250</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>tanh</td>\n",
       "      <td>...</td>\n",
       "      <td>0.199323</td>\n",
       "      <td>0.060319</td>\n",
       "      <td>1.502431</td>\n",
       "      <td>0.123619</td>\n",
       "      <td>0.120265</td>\n",
       "      <td>0.984317</td>\n",
       "      <td>0.603321</td>\n",
       "      <td>0.977476</td>\n",
       "      <td>0.607871</td>\n",
       "      <td>0.607871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>innerDNNClassifier</td>\n",
       "      <td>2250</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>tanh</td>\n",
       "      <td>...</td>\n",
       "      <td>0.135548</td>\n",
       "      <td>0.083472</td>\n",
       "      <td>1.409874</td>\n",
       "      <td>0.124749</td>\n",
       "      <td>0.124612</td>\n",
       "      <td>0.977860</td>\n",
       "      <td>0.632841</td>\n",
       "      <td>0.977080</td>\n",
       "      <td>0.676193</td>\n",
       "      <td>0.676193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>innerDNNClassifier</td>\n",
       "      <td>2250</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>tanh</td>\n",
       "      <td>...</td>\n",
       "      <td>0.154753</td>\n",
       "      <td>0.103826</td>\n",
       "      <td>1.282114</td>\n",
       "      <td>0.123358</td>\n",
       "      <td>0.122315</td>\n",
       "      <td>0.969557</td>\n",
       "      <td>0.662362</td>\n",
       "      <td>0.974532</td>\n",
       "      <td>0.689559</td>\n",
       "      <td>0.689559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>innerDNNClassifier</td>\n",
       "      <td>2250</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>tanh</td>\n",
       "      <td>...</td>\n",
       "      <td>0.301116</td>\n",
       "      <td>0.054464</td>\n",
       "      <td>1.375391</td>\n",
       "      <td>0.125634</td>\n",
       "      <td>0.123399</td>\n",
       "      <td>0.986162</td>\n",
       "      <td>0.634686</td>\n",
       "      <td>0.985057</td>\n",
       "      <td>0.659279</td>\n",
       "      <td>0.659279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>innerDNNClassifier</td>\n",
       "      <td>2250</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>tanh</td>\n",
       "      <td>...</td>\n",
       "      <td>0.160382</td>\n",
       "      <td>0.097038</td>\n",
       "      <td>1.305638</td>\n",
       "      <td>0.114893</td>\n",
       "      <td>0.115594</td>\n",
       "      <td>0.973247</td>\n",
       "      <td>0.656827</td>\n",
       "      <td>0.968717</td>\n",
       "      <td>0.676554</td>\n",
       "      <td>0.676554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>innerDNNClassifier</td>\n",
       "      <td>2250</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>tanh</td>\n",
       "      <td>...</td>\n",
       "      <td>0.186722</td>\n",
       "      <td>0.073626</td>\n",
       "      <td>1.475671</td>\n",
       "      <td>0.124697</td>\n",
       "      <td>0.121452</td>\n",
       "      <td>0.981550</td>\n",
       "      <td>0.601476</td>\n",
       "      <td>0.974307</td>\n",
       "      <td>0.640328</td>\n",
       "      <td>0.640328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>innerDNNClassifier</td>\n",
       "      <td>2250</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>tanh</td>\n",
       "      <td>...</td>\n",
       "      <td>0.186803</td>\n",
       "      <td>0.087133</td>\n",
       "      <td>1.339609</td>\n",
       "      <td>0.126859</td>\n",
       "      <td>0.125523</td>\n",
       "      <td>0.976015</td>\n",
       "      <td>0.649446</td>\n",
       "      <td>0.975412</td>\n",
       "      <td>0.679698</td>\n",
       "      <td>0.679698</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                model  epochs  fold  total_folds  batch_size  mval   \n",
       "0  innerDNNClassifier    2250     3            3         128  Mval  \\\n",
       "0  innerDNNClassifier    2250     2            3         128  Mval   \n",
       "0  innerDNNClassifier    2250     1            3         128  Mval   \n",
       "0  innerDNNClassifier    2250     3            3         128  Mval   \n",
       "0  innerDNNClassifier    2250     2            3         128  Mval   \n",
       "0  innerDNNClassifier    2250     1            3         128  Mval   \n",
       "0  innerDNNClassifier    2250     3            3         128  Mval   \n",
       "0  innerDNNClassifier    2250     2            3         128  Mval   \n",
       "0  innerDNNClassifier    2250     1            3         128  Mval   \n",
       "0  innerDNNClassifier    2250     3            3         128  Mval   \n",
       "0  innerDNNClassifier    2250     2            3         128  Mval   \n",
       "0  innerDNNClassifier    2250     1            3         128  Mval   \n",
       "0  innerDNNClassifier    2250     3            3         128  Mval   \n",
       "0  innerDNNClassifier    2250     2            3         128  Mval   \n",
       "0  innerDNNClassifier    2250     1            3         128  Mval   \n",
       "0  innerDNNClassifier    2250     3            3         128  Mval   \n",
       "0  innerDNNClassifier    2250     2            3         128  Mval   \n",
       "0  innerDNNClassifier    2250     1            3         128  Mval   \n",
       "0  innerDNNClassifier    2250     3            3         128  Mval   \n",
       "0  innerDNNClassifier    2250     2            3         128  Mval   \n",
       "0  innerDNNClassifier    2250     1            3         128  Mval   \n",
       "0  innerDNNClassifier    2250     3            3         128  Mval   \n",
       "0  innerDNNClassifier    2250     2            3         128  Mval   \n",
       "0  innerDNNClassifier    2250     1            3         128  Mval   \n",
       "0  innerDNNClassifier    2250     3            3         128  Mval   \n",
       "0  innerDNNClassifier    2250     2            3         128  Mval   \n",
       "0  innerDNNClassifier    2250     1            3         128  Mval   \n",
       "0  innerDNNClassifier    2250     3            3         128  Mval   \n",
       "0  innerDNNClassifier    2250     2            3         128  Mval   \n",
       "0  innerDNNClassifier    2250     1            3         128  Mval   \n",
       "\n",
       "   balance_alpha cpg_type  limma_features outer_cls_activ  ...   \n",
       "0            1.0      ALL             200            tanh  ...  \\\n",
       "0            1.0      ALL             200            tanh  ...   \n",
       "0            1.0      ALL             200            tanh  ...   \n",
       "0            1.0      ALL             200            tanh  ...   \n",
       "0            1.0      ALL             200            tanh  ...   \n",
       "0            1.0      ALL             200            tanh  ...   \n",
       "0            1.0      ALL             200            tanh  ...   \n",
       "0            1.0      ALL             200            tanh  ...   \n",
       "0            1.0      ALL             200            tanh  ...   \n",
       "0            1.0      ALL             200            tanh  ...   \n",
       "0            1.0      ALL             200            tanh  ...   \n",
       "0            1.0      ALL             200            tanh  ...   \n",
       "0            1.0      ALL             200            tanh  ...   \n",
       "0            1.0      ALL             200            tanh  ...   \n",
       "0            1.0      ALL             200            tanh  ...   \n",
       "0            1.0      ALL             200            tanh  ...   \n",
       "0            1.0      ALL             200            tanh  ...   \n",
       "0            1.0      ALL             200            tanh  ...   \n",
       "0            1.0      ALL             200            tanh  ...   \n",
       "0            1.0      ALL             200            tanh  ...   \n",
       "0            1.0      ALL             200            tanh  ...   \n",
       "0            1.0      ALL             200            tanh  ...   \n",
       "0            1.0      ALL             200            tanh  ...   \n",
       "0            1.0      ALL             200            tanh  ...   \n",
       "0            1.0      ALL             200            tanh  ...   \n",
       "0            1.0      ALL             200            tanh  ...   \n",
       "0            1.0      ALL             200            tanh  ...   \n",
       "0            1.0      ALL             200            tanh  ...   \n",
       "0            1.0      ALL             200            tanh  ...   \n",
       "0            1.0      ALL             200            tanh  ...   \n",
       "\n",
       "  test_recon_loss train_classification_loss  test_classification_loss   \n",
       "0        0.155804                  0.089293                  1.519166  \\\n",
       "0        0.163464                  0.057235                  1.410656   \n",
       "0        0.143579                  0.070557                  1.458056   \n",
       "0        0.159659                  0.085215                  1.449935   \n",
       "0        0.162721                  0.081335                  1.334476   \n",
       "0        0.147903                  0.071018                  1.444149   \n",
       "0        0.183957                  0.090087                  1.308106   \n",
       "0        0.210761                  0.063667                  1.427684   \n",
       "0        0.145002                  0.106360                  1.379983   \n",
       "0        0.156162                  0.072917                  1.476897   \n",
       "0        0.150495                  0.087918                  1.476599   \n",
       "0        0.206883                  0.066324                  1.396795   \n",
       "0        0.165727                  0.056766                  1.312577   \n",
       "0        0.181448                  0.078988                  1.369049   \n",
       "0        0.150045                  0.084277                  1.357063   \n",
       "0        0.144743                  0.072663                  1.441956   \n",
       "0        0.161723                  0.080719                  1.339395   \n",
       "0        0.208393                  0.035559                  1.377769   \n",
       "0        0.158443                  0.075046                  1.442824   \n",
       "0        0.170046                  0.092065                  1.434818   \n",
       "0        0.153185                  0.061641                  1.419275   \n",
       "0        0.166323                  0.136908                  1.432840   \n",
       "0        0.132295                  0.063783                  1.430563   \n",
       "0        0.199323                  0.060319                  1.502431   \n",
       "0        0.135548                  0.083472                  1.409874   \n",
       "0        0.154753                  0.103826                  1.282114   \n",
       "0        0.301116                  0.054464                  1.375391   \n",
       "0        0.160382                  0.097038                  1.305638   \n",
       "0        0.186722                  0.073626                  1.475671   \n",
       "0        0.186803                  0.087133                  1.339609   \n",
       "\n",
       "   train_kl_loss test_kl_loss accuracy_train accuracy_test auc_train   \n",
       "0       0.129897     0.128450       0.977860      0.603321  0.968487  \\\n",
       "0       0.121917     0.121305       0.984317      0.627306  0.980422   \n",
       "0       0.143317     0.142967       0.980627      0.605166  0.980181   \n",
       "0       0.123379     0.124970       0.976937      0.612546  0.966059   \n",
       "0       0.130138     0.130285       0.977860      0.645756  0.974470   \n",
       "0       0.122690     0.122498       0.982472      0.619926  0.968084   \n",
       "0       0.142313     0.138134       0.975092      0.654982  0.978033   \n",
       "0       0.121391     0.120084       0.983395      0.627306  0.979657   \n",
       "0       0.120226     0.119935       0.974170      0.634686  0.960303   \n",
       "0       0.142006     0.142912       0.980627      0.605166  0.973355   \n",
       "0       0.130808     0.130011       0.973247      0.605166  0.970548   \n",
       "0       0.119825     0.118426       0.982472      0.630996  0.976693   \n",
       "0       0.118049     0.117575       0.984317      0.658672  0.980111   \n",
       "0       0.126943     0.126882       0.978782      0.634686  0.974359   \n",
       "0       0.122666     0.122194       0.978782      0.645756  0.969592   \n",
       "0       0.143873     0.140224       0.979705      0.616236  0.988356   \n",
       "0       0.135920     0.139419       0.978782      0.640221  0.969168   \n",
       "0       0.126739     0.123418       0.990775      0.632841  0.986591   \n",
       "0       0.125091     0.127466       0.980627      0.621771  0.975669   \n",
       "0       0.143504     0.138440       0.975092      0.618081  0.968097   \n",
       "0       0.130429     0.126978       0.985240      0.618081  0.979848   \n",
       "0       0.123352     0.123205       0.957565      0.614391  0.975055   \n",
       "0       0.135125     0.136299       0.983395      0.619926  0.977330   \n",
       "0       0.123619     0.120265       0.984317      0.603321  0.977476   \n",
       "0       0.124749     0.124612       0.977860      0.632841  0.977080   \n",
       "0       0.123358     0.122315       0.969557      0.662362  0.974532   \n",
       "0       0.125634     0.123399       0.986162      0.634686  0.985057   \n",
       "0       0.114893     0.115594       0.973247      0.656827  0.968717   \n",
       "0       0.124697     0.121452       0.981550      0.601476  0.974307   \n",
       "0       0.126859     0.125523       0.976015      0.649446  0.975412   \n",
       "\n",
       "   auc_test  roc_auc_plot_test  \n",
       "0  0.633277           0.633277  \n",
       "0  0.657234           0.657234  \n",
       "0  0.624970           0.624970  \n",
       "0  0.662018           0.662018  \n",
       "0  0.646411           0.646411  \n",
       "0  0.630700           0.630700  \n",
       "0  0.649123           0.649123  \n",
       "0  0.632062           0.632062  \n",
       "0  0.666297           0.666297  \n",
       "0  0.655555           0.655555  \n",
       "0  0.652927           0.652927  \n",
       "0  0.665093           0.665093  \n",
       "0  0.662556           0.662556  \n",
       "0  0.677497           0.677497  \n",
       "0  0.648608           0.648608  \n",
       "0  0.611516           0.611516  \n",
       "0  0.659267           0.659267  \n",
       "0  0.640987           0.640987  \n",
       "0  0.649455           0.649455  \n",
       "0  0.647211           0.647211  \n",
       "0  0.624843           0.624843  \n",
       "0  0.671840           0.671840  \n",
       "0  0.641892           0.641892  \n",
       "0  0.607871           0.607871  \n",
       "0  0.676193           0.676193  \n",
       "0  0.689559           0.689559  \n",
       "0  0.659279           0.659279  \n",
       "0  0.676554           0.676554  \n",
       "0  0.640328           0.640328  \n",
       "0  0.679698           0.679698  \n",
       "\n",
       "[30 rows x 29 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas\n",
    "from HelperScriptsPY import helper_functions\n",
    "\n",
    "base_dir = \"10CV_DNN_RAW/10_CV_JointVAE\"\n",
    "CV_folders = [base_dir + \"/\" + x for x in os.listdir(base_dir) if os.path.isdir(base_dir + \"/\" + x)]\n",
    "target_folders = [path + \"/\" + x for path in CV_folders for x in os.listdir(path)]\n",
    "analysis_files = [x + \"/\" + i for x in target_folders for i in os.listdir(x) if \"_model_performance.csv\" in i]\n",
    "performance_lists = []\n",
    "\n",
    "for x in analysis_files:\n",
    "    dataset = pandas.read_csv(x)\n",
    "    dataset = helper_functions.drop_useless_column(dataset)\n",
    "    performance_lists.append(dataset)\n",
    "\n",
    "performance_df = pandas.concat(performance_lists)\n",
    "fold_data_JVAE = performance_df\n",
    "fold_data_JVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>epochs</th>\n",
       "      <th>fold</th>\n",
       "      <th>total_folds</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>mval</th>\n",
       "      <th>cpg_type</th>\n",
       "      <th>limma_features</th>\n",
       "      <th>outer_cls_activ</th>\n",
       "      <th>inner_act</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>classif_loss_fun</th>\n",
       "      <th>train_classification_loss</th>\n",
       "      <th>test_classification_loss</th>\n",
       "      <th>accuracy_train</th>\n",
       "      <th>accuracy_test</th>\n",
       "      <th>auc_train</th>\n",
       "      <th>auc_test</th>\n",
       "      <th>roc_auc_plot_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DNNclassfierSimpleBatch</td>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>0.007004</td>\n",
       "      <td>1.529326</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.654982</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.685694</td>\n",
       "      <td>0.685694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DNNclassfierSimpleBatch</td>\n",
       "      <td>1000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>0.007678</td>\n",
       "      <td>1.586364</td>\n",
       "      <td>0.999077</td>\n",
       "      <td>0.623616</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.695784</td>\n",
       "      <td>0.695784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DNNclassfierSimpleBatch</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>0.008847</td>\n",
       "      <td>1.583870</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.618081</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.665623</td>\n",
       "      <td>0.665623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DNNclassfierSimpleBatch</td>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>0.004705</td>\n",
       "      <td>1.867693</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.625461</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.641716</td>\n",
       "      <td>0.641716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DNNclassfierSimpleBatch</td>\n",
       "      <td>1000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>0.011785</td>\n",
       "      <td>1.574145</td>\n",
       "      <td>0.999077</td>\n",
       "      <td>0.645756</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.670752</td>\n",
       "      <td>0.670752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DNNclassfierSimpleBatch</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>0.011285</td>\n",
       "      <td>1.351409</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.664207</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.702027</td>\n",
       "      <td>0.702027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DNNclassfierSimpleBatch</td>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>0.009392</td>\n",
       "      <td>1.583184</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.649446</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.686357</td>\n",
       "      <td>0.686357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DNNclassfierSimpleBatch</td>\n",
       "      <td>1000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>0.016417</td>\n",
       "      <td>1.321607</td>\n",
       "      <td>0.999077</td>\n",
       "      <td>0.649446</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.713938</td>\n",
       "      <td>0.713938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DNNclassfierSimpleBatch</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>0.005376</td>\n",
       "      <td>1.719172</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.627306</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.658143</td>\n",
       "      <td>0.658143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DNNclassfierSimpleBatch</td>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>0.005293</td>\n",
       "      <td>1.505179</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.616236</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.663629</td>\n",
       "      <td>0.663629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DNNclassfierSimpleBatch</td>\n",
       "      <td>1000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>0.009694</td>\n",
       "      <td>1.404624</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666052</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.693894</td>\n",
       "      <td>0.693894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DNNclassfierSimpleBatch</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>0.008778</td>\n",
       "      <td>1.891122</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.594096</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.631053</td>\n",
       "      <td>0.631053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DNNclassfierSimpleBatch</td>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>0.012278</td>\n",
       "      <td>1.529657</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.616236</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.641562</td>\n",
       "      <td>0.641562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DNNclassfierSimpleBatch</td>\n",
       "      <td>1000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>0.008758</td>\n",
       "      <td>1.544972</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.642066</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.676848</td>\n",
       "      <td>0.676848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DNNclassfierSimpleBatch</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>0.017434</td>\n",
       "      <td>1.335530</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.651292</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.707133</td>\n",
       "      <td>0.707133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DNNclassfierSimpleBatch</td>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>0.006967</td>\n",
       "      <td>1.563744</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.653137</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.679734</td>\n",
       "      <td>0.679734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DNNclassfierSimpleBatch</td>\n",
       "      <td>1000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>0.007442</td>\n",
       "      <td>1.515344</td>\n",
       "      <td>0.999077</td>\n",
       "      <td>0.662362</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.674025</td>\n",
       "      <td>0.674025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DNNclassfierSimpleBatch</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>0.018920</td>\n",
       "      <td>1.573668</td>\n",
       "      <td>0.996310</td>\n",
       "      <td>0.623616</td>\n",
       "      <td>0.999968</td>\n",
       "      <td>0.654833</td>\n",
       "      <td>0.654833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DNNclassfierSimpleBatch</td>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>0.014585</td>\n",
       "      <td>1.376894</td>\n",
       "      <td>0.999077</td>\n",
       "      <td>0.638376</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.688432</td>\n",
       "      <td>0.688432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DNNclassfierSimpleBatch</td>\n",
       "      <td>1000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>0.006782</td>\n",
       "      <td>1.493430</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.640221</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.665023</td>\n",
       "      <td>0.665023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DNNclassfierSimpleBatch</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>0.017388</td>\n",
       "      <td>1.388660</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.621771</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.674057</td>\n",
       "      <td>0.674057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DNNclassfierSimpleBatch</td>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>0.022302</td>\n",
       "      <td>1.542223</td>\n",
       "      <td>0.996310</td>\n",
       "      <td>0.629151</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.637390</td>\n",
       "      <td>0.637390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DNNclassfierSimpleBatch</td>\n",
       "      <td>1000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>0.004371</td>\n",
       "      <td>1.633776</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.632841</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666976</td>\n",
       "      <td>0.666976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DNNclassfierSimpleBatch</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>0.013896</td>\n",
       "      <td>1.522596</td>\n",
       "      <td>0.999077</td>\n",
       "      <td>0.643911</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.658109</td>\n",
       "      <td>0.658109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DNNclassfierSimpleBatch</td>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>0.009859</td>\n",
       "      <td>1.331870</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.669742</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.686847</td>\n",
       "      <td>0.686847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DNNclassfierSimpleBatch</td>\n",
       "      <td>1000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>0.006859</td>\n",
       "      <td>1.595531</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.651292</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.662576</td>\n",
       "      <td>0.662576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DNNclassfierSimpleBatch</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>0.006663</td>\n",
       "      <td>1.573026</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.625461</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.673871</td>\n",
       "      <td>0.673871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DNNclassfierSimpleBatch</td>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>0.007061</td>\n",
       "      <td>1.529858</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.649446</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.677470</td>\n",
       "      <td>0.677470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DNNclassfierSimpleBatch</td>\n",
       "      <td>1000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>0.008726</td>\n",
       "      <td>1.442364</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.664207</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.685700</td>\n",
       "      <td>0.685700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DNNclassfierSimpleBatch</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>Mval</td>\n",
       "      <td>ALL</td>\n",
       "      <td>200</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>0.007674</td>\n",
       "      <td>1.870454</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.594096</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.629860</td>\n",
       "      <td>0.629860</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     model  epochs  fold  total_folds  batch_size  mval   \n",
       "0  DNNclassfierSimpleBatch    1000     3            3         128  Mval  \\\n",
       "0  DNNclassfierSimpleBatch    1000     2            3         128  Mval   \n",
       "0  DNNclassfierSimpleBatch    1000     1            3         128  Mval   \n",
       "0  DNNclassfierSimpleBatch    1000     3            3         128  Mval   \n",
       "0  DNNclassfierSimpleBatch    1000     2            3         128  Mval   \n",
       "0  DNNclassfierSimpleBatch    1000     1            3         128  Mval   \n",
       "0  DNNclassfierSimpleBatch    1000     3            3         128  Mval   \n",
       "0  DNNclassfierSimpleBatch    1000     2            3         128  Mval   \n",
       "0  DNNclassfierSimpleBatch    1000     1            3         128  Mval   \n",
       "0  DNNclassfierSimpleBatch    1000     3            3         128  Mval   \n",
       "0  DNNclassfierSimpleBatch    1000     2            3         128  Mval   \n",
       "0  DNNclassfierSimpleBatch    1000     1            3         128  Mval   \n",
       "0  DNNclassfierSimpleBatch    1000     3            3         128  Mval   \n",
       "0  DNNclassfierSimpleBatch    1000     2            3         128  Mval   \n",
       "0  DNNclassfierSimpleBatch    1000     1            3         128  Mval   \n",
       "0  DNNclassfierSimpleBatch    1000     3            3         128  Mval   \n",
       "0  DNNclassfierSimpleBatch    1000     2            3         128  Mval   \n",
       "0  DNNclassfierSimpleBatch    1000     1            3         128  Mval   \n",
       "0  DNNclassfierSimpleBatch    1000     3            3         128  Mval   \n",
       "0  DNNclassfierSimpleBatch    1000     2            3         128  Mval   \n",
       "0  DNNclassfierSimpleBatch    1000     1            3         128  Mval   \n",
       "0  DNNclassfierSimpleBatch    1000     3            3         128  Mval   \n",
       "0  DNNclassfierSimpleBatch    1000     2            3         128  Mval   \n",
       "0  DNNclassfierSimpleBatch    1000     1            3         128  Mval   \n",
       "0  DNNclassfierSimpleBatch    1000     3            3         128  Mval   \n",
       "0  DNNclassfierSimpleBatch    1000     2            3         128  Mval   \n",
       "0  DNNclassfierSimpleBatch    1000     1            3         128  Mval   \n",
       "0  DNNclassfierSimpleBatch    1000     3            3         128  Mval   \n",
       "0  DNNclassfierSimpleBatch    1000     2            3         128  Mval   \n",
       "0  DNNclassfierSimpleBatch    1000     1            3         128  Mval   \n",
       "\n",
       "  cpg_type  limma_features outer_cls_activ inner_act  learning_rate   \n",
       "0      ALL             200         sigmoid      relu         0.0001  \\\n",
       "0      ALL             200         sigmoid      relu         0.0001   \n",
       "0      ALL             200         sigmoid      relu         0.0001   \n",
       "0      ALL             200         sigmoid      relu         0.0001   \n",
       "0      ALL             200         sigmoid      relu         0.0001   \n",
       "0      ALL             200         sigmoid      relu         0.0001   \n",
       "0      ALL             200         sigmoid      relu         0.0001   \n",
       "0      ALL             200         sigmoid      relu         0.0001   \n",
       "0      ALL             200         sigmoid      relu         0.0001   \n",
       "0      ALL             200         sigmoid      relu         0.0001   \n",
       "0      ALL             200         sigmoid      relu         0.0001   \n",
       "0      ALL             200         sigmoid      relu         0.0001   \n",
       "0      ALL             200         sigmoid      relu         0.0001   \n",
       "0      ALL             200         sigmoid      relu         0.0001   \n",
       "0      ALL             200         sigmoid      relu         0.0001   \n",
       "0      ALL             200         sigmoid      relu         0.0001   \n",
       "0      ALL             200         sigmoid      relu         0.0001   \n",
       "0      ALL             200         sigmoid      relu         0.0001   \n",
       "0      ALL             200         sigmoid      relu         0.0001   \n",
       "0      ALL             200         sigmoid      relu         0.0001   \n",
       "0      ALL             200         sigmoid      relu         0.0001   \n",
       "0      ALL             200         sigmoid      relu         0.0001   \n",
       "0      ALL             200         sigmoid      relu         0.0001   \n",
       "0      ALL             200         sigmoid      relu         0.0001   \n",
       "0      ALL             200         sigmoid      relu         0.0001   \n",
       "0      ALL             200         sigmoid      relu         0.0001   \n",
       "0      ALL             200         sigmoid      relu         0.0001   \n",
       "0      ALL             200         sigmoid      relu         0.0001   \n",
       "0      ALL             200         sigmoid      relu         0.0001   \n",
       "0      ALL             200         sigmoid      relu         0.0001   \n",
       "\n",
       "      classif_loss_fun  train_classification_loss  test_classification_loss   \n",
       "0  binary_crossentropy                   0.007004                  1.529326  \\\n",
       "0  binary_crossentropy                   0.007678                  1.586364   \n",
       "0  binary_crossentropy                   0.008847                  1.583870   \n",
       "0  binary_crossentropy                   0.004705                  1.867693   \n",
       "0  binary_crossentropy                   0.011785                  1.574145   \n",
       "0  binary_crossentropy                   0.011285                  1.351409   \n",
       "0  binary_crossentropy                   0.009392                  1.583184   \n",
       "0  binary_crossentropy                   0.016417                  1.321607   \n",
       "0  binary_crossentropy                   0.005376                  1.719172   \n",
       "0  binary_crossentropy                   0.005293                  1.505179   \n",
       "0  binary_crossentropy                   0.009694                  1.404624   \n",
       "0  binary_crossentropy                   0.008778                  1.891122   \n",
       "0  binary_crossentropy                   0.012278                  1.529657   \n",
       "0  binary_crossentropy                   0.008758                  1.544972   \n",
       "0  binary_crossentropy                   0.017434                  1.335530   \n",
       "0  binary_crossentropy                   0.006967                  1.563744   \n",
       "0  binary_crossentropy                   0.007442                  1.515344   \n",
       "0  binary_crossentropy                   0.018920                  1.573668   \n",
       "0  binary_crossentropy                   0.014585                  1.376894   \n",
       "0  binary_crossentropy                   0.006782                  1.493430   \n",
       "0  binary_crossentropy                   0.017388                  1.388660   \n",
       "0  binary_crossentropy                   0.022302                  1.542223   \n",
       "0  binary_crossentropy                   0.004371                  1.633776   \n",
       "0  binary_crossentropy                   0.013896                  1.522596   \n",
       "0  binary_crossentropy                   0.009859                  1.331870   \n",
       "0  binary_crossentropy                   0.006859                  1.595531   \n",
       "0  binary_crossentropy                   0.006663                  1.573026   \n",
       "0  binary_crossentropy                   0.007061                  1.529858   \n",
       "0  binary_crossentropy                   0.008726                  1.442364   \n",
       "0  binary_crossentropy                   0.007674                  1.870454   \n",
       "\n",
       "   accuracy_train  accuracy_test  auc_train  auc_test  roc_auc_plot_test  \n",
       "0        1.000000       0.654982   1.000000  0.685694           0.685694  \n",
       "0        0.999077       0.623616   0.999989  0.695784           0.695784  \n",
       "0        1.000000       0.618081   1.000000  0.665623           0.665623  \n",
       "0        1.000000       0.625461   1.000000  0.641716           0.641716  \n",
       "0        0.999077       0.645756   1.000000  0.670752           0.670752  \n",
       "0        1.000000       0.664207   1.000000  0.702027           0.702027  \n",
       "0        1.000000       0.649446   1.000000  0.686357           0.686357  \n",
       "0        0.999077       0.649446   1.000000  0.713938           0.713938  \n",
       "0        1.000000       0.627306   1.000000  0.658143           0.658143  \n",
       "0        1.000000       0.616236   1.000000  0.663629           0.663629  \n",
       "0        1.000000       0.666052   1.000000  0.693894           0.693894  \n",
       "0        1.000000       0.594096   1.000000  0.631053           0.631053  \n",
       "0        1.000000       0.616236   1.000000  0.641562           0.641562  \n",
       "0        1.000000       0.642066   1.000000  0.676848           0.676848  \n",
       "0        1.000000       0.651292   1.000000  0.707133           0.707133  \n",
       "0        1.000000       0.653137   1.000000  0.679734           0.679734  \n",
       "0        0.999077       0.662362   1.000000  0.674025           0.674025  \n",
       "0        0.996310       0.623616   0.999968  0.654833           0.654833  \n",
       "0        0.999077       0.638376   1.000000  0.688432           0.688432  \n",
       "0        1.000000       0.640221   1.000000  0.665023           0.665023  \n",
       "0        1.000000       0.621771   1.000000  0.674057           0.674057  \n",
       "0        0.996310       0.629151   0.999979  0.637390           0.637390  \n",
       "0        1.000000       0.632841   1.000000  0.666976           0.666976  \n",
       "0        0.999077       0.643911   1.000000  0.658109           0.658109  \n",
       "0        1.000000       0.669742   1.000000  0.686847           0.686847  \n",
       "0        1.000000       0.651292   1.000000  0.662576           0.662576  \n",
       "0        1.000000       0.625461   1.000000  0.673871           0.673871  \n",
       "0        1.000000       0.649446   1.000000  0.677470           0.677470  \n",
       "0        1.000000       0.664207   1.000000  0.685700           0.685700  \n",
       "0        1.000000       0.594096   1.000000  0.629860           0.629860  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas\n",
    "from HelperScriptsPY import helper_functions\n",
    "\n",
    "base_dir = \"10CV_DNN_RAW/10_CV_SmallDNN\"\n",
    "CV_folders = [base_dir + \"/\" + x for x in os.listdir(base_dir) if os.path.isdir(base_dir + \"/\" + x)]\n",
    "target_folders = [path + \"/\" + x for path in CV_folders for x in os.listdir(path)]\n",
    "analysis_files = [x + \"/\" + i for x in target_folders for i in os.listdir(x) if \"_model_performance.csv\" in i]\n",
    "performance_lists = []\n",
    "\n",
    "for x in analysis_files:\n",
    "    dataset = pandas.read_csv(x)\n",
    "    dataset = helper_functions.drop_useless_column(dataset)\n",
    "    performance_lists.append(dataset)\n",
    "\n",
    "performance_df = pandas.concat(performance_lists)\n",
    "fold_data_DNN = performance_df\n",
    "fold_data_DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Fold</th>\n",
       "      <th>Feature selection</th>\n",
       "      <th>10 CV accuracy (train)</th>\n",
       "      <th>10 CV accuracy (hold-out)</th>\n",
       "      <th>10 CV AUC (train)</th>\n",
       "      <th>10 CV AUC (hold-out)</th>\n",
       "      <th>Data harmonization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM (RBF kernel)</td>\n",
       "      <td>3</td>\n",
       "      <td>Top 200 Limma</td>\n",
       "      <td>0.678044</td>\n",
       "      <td>0.675277</td>\n",
       "      <td>0.768813</td>\n",
       "      <td>0.704630</td>\n",
       "      <td>batch-level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM (RBF kernel)</td>\n",
       "      <td>2</td>\n",
       "      <td>Top 200 Limma</td>\n",
       "      <td>0.673432</td>\n",
       "      <td>0.682657</td>\n",
       "      <td>0.792484</td>\n",
       "      <td>0.743991</td>\n",
       "      <td>batch-level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM (RBF kernel)</td>\n",
       "      <td>1</td>\n",
       "      <td>Top 200 Limma</td>\n",
       "      <td>0.677122</td>\n",
       "      <td>0.673432</td>\n",
       "      <td>0.762806</td>\n",
       "      <td>0.702658</td>\n",
       "      <td>batch-level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM (RBF kernel)</td>\n",
       "      <td>3</td>\n",
       "      <td>Top 200 Limma</td>\n",
       "      <td>0.944649</td>\n",
       "      <td>0.671587</td>\n",
       "      <td>0.989190</td>\n",
       "      <td>0.709857</td>\n",
       "      <td>batch-level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM (RBF kernel)</td>\n",
       "      <td>2</td>\n",
       "      <td>Top 200 Limma</td>\n",
       "      <td>0.868081</td>\n",
       "      <td>0.688192</td>\n",
       "      <td>0.976227</td>\n",
       "      <td>0.716739</td>\n",
       "      <td>batch-level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>2</td>\n",
       "      <td>Top 200 Limma</td>\n",
       "      <td>0.863469</td>\n",
       "      <td>0.667897</td>\n",
       "      <td>0.946032</td>\n",
       "      <td>0.684510</td>\n",
       "      <td>batch-level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>1</td>\n",
       "      <td>Top 200 Limma</td>\n",
       "      <td>0.869004</td>\n",
       "      <td>0.618081</td>\n",
       "      <td>0.951365</td>\n",
       "      <td>0.669604</td>\n",
       "      <td>batch-level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>3</td>\n",
       "      <td>Top 200 Limma</td>\n",
       "      <td>0.869926</td>\n",
       "      <td>0.643911</td>\n",
       "      <td>0.950153</td>\n",
       "      <td>0.643472</td>\n",
       "      <td>batch-level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>2</td>\n",
       "      <td>Top 200 Limma</td>\n",
       "      <td>0.866236</td>\n",
       "      <td>0.619926</td>\n",
       "      <td>0.943966</td>\n",
       "      <td>0.652925</td>\n",
       "      <td>batch-level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>1</td>\n",
       "      <td>Top 200 Limma</td>\n",
       "      <td>0.846863</td>\n",
       "      <td>0.667897</td>\n",
       "      <td>0.937493</td>\n",
       "      <td>0.700641</td>\n",
       "      <td>batch-level</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>630 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model  Fold Feature selection  10 CV accuracy (train)   \n",
       "0   SVM (RBF kernel)     3     Top 200 Limma                0.678044  \\\n",
       "0   SVM (RBF kernel)     2     Top 200 Limma                0.673432   \n",
       "0   SVM (RBF kernel)     1     Top 200 Limma                0.677122   \n",
       "0   SVM (RBF kernel)     3     Top 200 Limma                0.944649   \n",
       "0   SVM (RBF kernel)     2     Top 200 Limma                0.868081   \n",
       "..               ...   ...               ...                     ...   \n",
       "0           AdaBoost     2     Top 200 Limma                0.863469   \n",
       "0           AdaBoost     1     Top 200 Limma                0.869004   \n",
       "0           AdaBoost     3     Top 200 Limma                0.869926   \n",
       "0           AdaBoost     2     Top 200 Limma                0.866236   \n",
       "0           AdaBoost     1     Top 200 Limma                0.846863   \n",
       "\n",
       "    10 CV accuracy (hold-out)  10 CV AUC (train)  10 CV AUC (hold-out)   \n",
       "0                    0.675277           0.768813              0.704630  \\\n",
       "0                    0.682657           0.792484              0.743991   \n",
       "0                    0.673432           0.762806              0.702658   \n",
       "0                    0.671587           0.989190              0.709857   \n",
       "0                    0.688192           0.976227              0.716739   \n",
       "..                        ...                ...                   ...   \n",
       "0                    0.667897           0.946032              0.684510   \n",
       "0                    0.618081           0.951365              0.669604   \n",
       "0                    0.643911           0.950153              0.643472   \n",
       "0                    0.619926           0.943966              0.652925   \n",
       "0                    0.667897           0.937493              0.700641   \n",
       "\n",
       "   Data harmonization  \n",
       "0         batch-level  \n",
       "0         batch-level  \n",
       "0         batch-level  \n",
       "0         batch-level  \n",
       "0         batch-level  \n",
       "..                ...  \n",
       "0         batch-level  \n",
       "0         batch-level  \n",
       "0         batch-level  \n",
       "0         batch-level  \n",
       "0         batch-level  \n",
       "\n",
       "[630 rows x 8 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold_data_JAE[\"model\"] = \"JointAE-classifier\"\n",
    "fold_data_JVAE[\"model\"] = \"JointVAE-classifier\"\n",
    "fold_data_DNN[\"model\"] = \"DNN classifier\"\n",
    "merged_fold_data_limma = pandas.concat([fold_data_ML, fold_data_JAE, fold_data_JVAE, fold_data_DNN])\n",
    "merged_fold_data_limma[\"harmonization\"] = \"batch-level\"\n",
    "merged_fold_data_limma = merged_fold_data_limma[[\"model\", \"fold\", \"cpg_type\", \"accuracy_train\", \"accuracy_test\", \"auc_train\", \"auc_test\", \"harmonization\"]]\n",
    "merged_fold_data_limma = merged_fold_data_limma.sort_values(by=[\"harmonization\", \"model\", \"cpg_type\"], ascending=False)\n",
    "merged_fold_data_limma.replace({'model': {\n",
    "    \"SVM_c_RBF_15\": \"SVM (RBF kernel)\",\n",
    "    \"SVM_c\": \"SVM (Linear kernel)\",\n",
    "    \"RidgeLogisticRegr\": \"Logistic regression ('L2')\",\n",
    "    \"RandomForest\": \"Random forest\",\n",
    "    \"LogisticRegr\": \"Logistic regression (no regularization)\",\n",
    "    \"Lasso_classifier\": \"Logistic regression ('L1')\",\n",
    "    \"Elastic_net_classifier\": \"Logistic regression ('L1L2'/Elastic net)\",\n",
    "    \"DecisionTree\": \"Decision tree\"\n",
    "}, \"cpg_type\":{\n",
    "    \"ALL\":\"Top 200 Limma\"\n",
    "}}, inplace=True)\n",
    "merged_fold_data_limma.columns = [\"Model\",\n",
    "                                 \"Fold\",\n",
    "                                 \"Feature selection\", \n",
    "                                 \"10 CV accuracy (train)\", \n",
    "                                 \"10 CV accuracy (hold-out)\", \n",
    "                                 \"10 CV AUC (train)\",\n",
    "                                 \"10 CV AUC (hold-out)\",\n",
    "                                 \"Data harmonization\"]\n",
    "merged_fold_data_limma.to_csv(\"merged_fold_data_10CV_Limma.csv\")\n",
    "merged_fold_data_limma\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Final tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Methylation value</th>\n",
       "      <th>10 CV accuracy (train)</th>\n",
       "      <th>10 CV accuracy (hold-out)</th>\n",
       "      <th>10 CV AUC (train)</th>\n",
       "      <th>10 CV AUC (hold-out)</th>\n",
       "      <th>Selected CpGs (features)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>Betaval</td>\n",
       "      <td>0.849</td>\n",
       "      <td>0.679</td>\n",
       "      <td>0.938</td>\n",
       "      <td>0.733</td>\n",
       "      <td>Top 200 Consistent (Pre-selected)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>Mval</td>\n",
       "      <td>0.852</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.938</td>\n",
       "      <td>0.737</td>\n",
       "      <td>Top 200 Consistent (Pre-selected)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision tree</td>\n",
       "      <td>Betaval</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.624</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.612</td>\n",
       "      <td>Top 200 Consistent (Pre-selected)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision tree</td>\n",
       "      <td>Mval</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.622</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.609</td>\n",
       "      <td>Top 200 Consistent (Pre-selected)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic regression ('L1L2'/Elastic net)</td>\n",
       "      <td>Betaval</td>\n",
       "      <td>0.741</td>\n",
       "      <td>0.712</td>\n",
       "      <td>0.817</td>\n",
       "      <td>0.775</td>\n",
       "      <td>Top 200 Consistent (Pre-selected)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Logistic regression ('L1L2'/Elastic net)</td>\n",
       "      <td>Mval</td>\n",
       "      <td>0.849</td>\n",
       "      <td>0.739</td>\n",
       "      <td>0.926</td>\n",
       "      <td>0.816</td>\n",
       "      <td>Top 200 Consistent (Pre-selected)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Logistic regression ('L1')</td>\n",
       "      <td>Betaval</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.764</td>\n",
       "      <td>Top 200 Consistent (Pre-selected)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Logistic regression ('L1')</td>\n",
       "      <td>Mval</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.924</td>\n",
       "      <td>0.815</td>\n",
       "      <td>Top 200 Consistent (Pre-selected)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Logistic regression (no regularization)</td>\n",
       "      <td>Betaval</td>\n",
       "      <td>0.852</td>\n",
       "      <td>0.730</td>\n",
       "      <td>0.929</td>\n",
       "      <td>0.802</td>\n",
       "      <td>Top 200 Consistent (Pre-selected)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Logistic regression (no regularization)</td>\n",
       "      <td>Mval</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.932</td>\n",
       "      <td>0.800</td>\n",
       "      <td>Top 200 Consistent (Pre-selected)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Random forest</td>\n",
       "      <td>Betaval</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.707</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.762</td>\n",
       "      <td>Top 200 Consistent (Pre-selected)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Random forest</td>\n",
       "      <td>Mval</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.709</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.760</td>\n",
       "      <td>Top 200 Consistent (Pre-selected)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Logistic regression ('L2')</td>\n",
       "      <td>Betaval</td>\n",
       "      <td>0.748</td>\n",
       "      <td>0.722</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.786</td>\n",
       "      <td>Top 200 Consistent (Pre-selected)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Logistic regression ('L2')</td>\n",
       "      <td>Mval</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.815</td>\n",
       "      <td>Top 200 Consistent (Pre-selected)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SVM (Linear kernel)</td>\n",
       "      <td>Betaval</td>\n",
       "      <td>0.747</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.789</td>\n",
       "      <td>Top 200 Consistent (Pre-selected)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SVM (Linear kernel)</td>\n",
       "      <td>Mval</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.730</td>\n",
       "      <td>0.920</td>\n",
       "      <td>0.802</td>\n",
       "      <td>Top 200 Consistent (Pre-selected)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>SVM (RBF kernel)</td>\n",
       "      <td>Betaval</td>\n",
       "      <td>0.677</td>\n",
       "      <td>0.677</td>\n",
       "      <td>0.731</td>\n",
       "      <td>0.719</td>\n",
       "      <td>Top 200 Consistent (Pre-selected)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>SVM (RBF kernel)</td>\n",
       "      <td>Mval</td>\n",
       "      <td>0.919</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.790</td>\n",
       "      <td>Top 200 Consistent (Pre-selected)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>Betaval</td>\n",
       "      <td>0.859</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.943</td>\n",
       "      <td>0.684</td>\n",
       "      <td>Top 200 Limma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>Mval</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.649</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.683</td>\n",
       "      <td>Top 200 Limma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Decision tree</td>\n",
       "      <td>Betaval</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.614</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.601</td>\n",
       "      <td>Top 200 Limma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Decision tree</td>\n",
       "      <td>Mval</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.615</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.602</td>\n",
       "      <td>Top 200 Limma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Logistic regression ('L1L2'/Elastic net)</td>\n",
       "      <td>Betaval</td>\n",
       "      <td>0.749</td>\n",
       "      <td>0.669</td>\n",
       "      <td>0.826</td>\n",
       "      <td>0.716</td>\n",
       "      <td>Top 200 Limma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Logistic regression ('L1L2'/Elastic net)</td>\n",
       "      <td>Mval</td>\n",
       "      <td>0.813</td>\n",
       "      <td>0.646</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.675</td>\n",
       "      <td>Top 200 Limma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Logistic regression ('L1')</td>\n",
       "      <td>Betaval</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.666</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.706</td>\n",
       "      <td>Top 200 Limma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Logistic regression ('L1')</td>\n",
       "      <td>Mval</td>\n",
       "      <td>0.807</td>\n",
       "      <td>0.643</td>\n",
       "      <td>0.882</td>\n",
       "      <td>0.677</td>\n",
       "      <td>Top 200 Limma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Logistic regression (no regularization)</td>\n",
       "      <td>Betaval</td>\n",
       "      <td>0.836</td>\n",
       "      <td>0.638</td>\n",
       "      <td>0.910</td>\n",
       "      <td>0.670</td>\n",
       "      <td>Top 200 Limma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Logistic regression (no regularization)</td>\n",
       "      <td>Mval</td>\n",
       "      <td>0.842</td>\n",
       "      <td>0.633</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.669</td>\n",
       "      <td>Top 200 Limma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Random forest</td>\n",
       "      <td>Betaval</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.680</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.726</td>\n",
       "      <td>Top 200 Limma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Random forest</td>\n",
       "      <td>Mval</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.687</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.731</td>\n",
       "      <td>Top 200 Limma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Logistic regression ('L2')</td>\n",
       "      <td>Betaval</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.673</td>\n",
       "      <td>0.826</td>\n",
       "      <td>0.719</td>\n",
       "      <td>Top 200 Limma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Logistic regression ('L2')</td>\n",
       "      <td>Mval</td>\n",
       "      <td>0.841</td>\n",
       "      <td>0.648</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.681</td>\n",
       "      <td>Top 200 Limma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>SVM (Linear kernel)</td>\n",
       "      <td>Betaval</td>\n",
       "      <td>0.762</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.699</td>\n",
       "      <td>Top 200 Limma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>SVM (Linear kernel)</td>\n",
       "      <td>Mval</td>\n",
       "      <td>0.852</td>\n",
       "      <td>0.635</td>\n",
       "      <td>0.902</td>\n",
       "      <td>0.667</td>\n",
       "      <td>Top 200 Limma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>SVM (RBF kernel)</td>\n",
       "      <td>Betaval</td>\n",
       "      <td>0.678</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.773</td>\n",
       "      <td>0.718</td>\n",
       "      <td>Top 200 Limma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>SVM (RBF kernel)</td>\n",
       "      <td>Mval</td>\n",
       "      <td>0.928</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.706</td>\n",
       "      <td>Top 200 Limma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Logistic regression ('L1L2'/Elastic net)</td>\n",
       "      <td>Betaval</td>\n",
       "      <td>0.971</td>\n",
       "      <td>0.668</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.706</td>\n",
       "      <td>Top 10K Limma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Logistic regression ('L1L2'/Elastic net)</td>\n",
       "      <td>Mval</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.668</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.707</td>\n",
       "      <td>Top 10K Limma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Logistic regression ('L1')</td>\n",
       "      <td>Betaval</td>\n",
       "      <td>0.940</td>\n",
       "      <td>0.657</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.694</td>\n",
       "      <td>Top 10K Limma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Logistic regression ('L1')</td>\n",
       "      <td>Mval</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.668</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.708</td>\n",
       "      <td>Top 10K Limma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Logistic regression ('L2')</td>\n",
       "      <td>Betaval</td>\n",
       "      <td>0.998</td>\n",
       "      <td>0.660</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.701</td>\n",
       "      <td>Top 10K Limma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Logistic regression ('L2')</td>\n",
       "      <td>Mval</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.667</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.699</td>\n",
       "      <td>Top 10K Limma</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Model Methylation value   \n",
       "0                                   AdaBoost           Betaval  \\\n",
       "1                                   AdaBoost              Mval   \n",
       "2                              Decision tree           Betaval   \n",
       "3                              Decision tree              Mval   \n",
       "4   Logistic regression ('L1L2'/Elastic net)           Betaval   \n",
       "5   Logistic regression ('L1L2'/Elastic net)              Mval   \n",
       "6                 Logistic regression ('L1')           Betaval   \n",
       "7                 Logistic regression ('L1')              Mval   \n",
       "8    Logistic regression (no regularization)           Betaval   \n",
       "9    Logistic regression (no regularization)              Mval   \n",
       "10                             Random forest           Betaval   \n",
       "11                             Random forest              Mval   \n",
       "12                Logistic regression ('L2')           Betaval   \n",
       "13                Logistic regression ('L2')              Mval   \n",
       "14                       SVM (Linear kernel)           Betaval   \n",
       "15                       SVM (Linear kernel)              Mval   \n",
       "16                          SVM (RBF kernel)           Betaval   \n",
       "17                          SVM (RBF kernel)              Mval   \n",
       "18                                  AdaBoost           Betaval   \n",
       "19                                  AdaBoost              Mval   \n",
       "20                             Decision tree           Betaval   \n",
       "21                             Decision tree              Mval   \n",
       "22  Logistic regression ('L1L2'/Elastic net)           Betaval   \n",
       "23  Logistic regression ('L1L2'/Elastic net)              Mval   \n",
       "24                Logistic regression ('L1')           Betaval   \n",
       "25                Logistic regression ('L1')              Mval   \n",
       "26   Logistic regression (no regularization)           Betaval   \n",
       "27   Logistic regression (no regularization)              Mval   \n",
       "28                             Random forest           Betaval   \n",
       "29                             Random forest              Mval   \n",
       "30                Logistic regression ('L2')           Betaval   \n",
       "31                Logistic regression ('L2')              Mval   \n",
       "32                       SVM (Linear kernel)           Betaval   \n",
       "33                       SVM (Linear kernel)              Mval   \n",
       "34                          SVM (RBF kernel)           Betaval   \n",
       "35                          SVM (RBF kernel)              Mval   \n",
       "36  Logistic regression ('L1L2'/Elastic net)           Betaval   \n",
       "37  Logistic regression ('L1L2'/Elastic net)              Mval   \n",
       "38                Logistic regression ('L1')           Betaval   \n",
       "39                Logistic regression ('L1')              Mval   \n",
       "40                Logistic regression ('L2')           Betaval   \n",
       "41                Logistic regression ('L2')              Mval   \n",
       "\n",
       "    10 CV accuracy (train)  10 CV accuracy (hold-out)  10 CV AUC (train)   \n",
       "0                    0.849                      0.679              0.938  \\\n",
       "1                    0.852                      0.680              0.938   \n",
       "2                    1.000                      0.624              1.000   \n",
       "3                    1.000                      0.622              1.000   \n",
       "4                    0.741                      0.712              0.817   \n",
       "5                    0.849                      0.739              0.926   \n",
       "6                    0.738                      0.703              0.814   \n",
       "7                    0.845                      0.738              0.924   \n",
       "8                    0.852                      0.730              0.929   \n",
       "9                    0.856                      0.732              0.932   \n",
       "10                   1.000                      0.707              1.000   \n",
       "11                   1.000                      0.709              1.000   \n",
       "12                   0.748                      0.722              0.825   \n",
       "13                   0.853                      0.740              0.930   \n",
       "14                   0.747                      0.710              0.851   \n",
       "15                   0.867                      0.730              0.920   \n",
       "16                   0.677                      0.677              0.731   \n",
       "17                   0.919                      0.727              0.988   \n",
       "18                   0.859                      0.652              0.943   \n",
       "19                   0.870                      0.649              0.950   \n",
       "20                   1.000                      0.614              1.000   \n",
       "21                   1.000                      0.615              1.000   \n",
       "22                   0.749                      0.669              0.826   \n",
       "23                   0.813                      0.646              0.887   \n",
       "24                   0.754                      0.666              0.830   \n",
       "25                   0.807                      0.643              0.882   \n",
       "26                   0.836                      0.638              0.910   \n",
       "27                   0.842                      0.633              0.915   \n",
       "28                   1.000                      0.680              1.000   \n",
       "29                   1.000                      0.687              1.000   \n",
       "30                   0.750                      0.673              0.826   \n",
       "31                   0.841                      0.648              0.915   \n",
       "32                   0.762                      0.675              0.851   \n",
       "33                   0.852                      0.635              0.902   \n",
       "34                   0.678                      0.676              0.773   \n",
       "35                   0.928                      0.676              0.988   \n",
       "36                   0.971                      0.668              0.996   \n",
       "37                   1.000                      0.668              1.000   \n",
       "38                   0.940                      0.657              0.987   \n",
       "39                   0.999                      0.668              1.000   \n",
       "40                   0.998                      0.660              0.999   \n",
       "41                   1.000                      0.667              1.000   \n",
       "\n",
       "    10 CV AUC (hold-out)           Selected CpGs (features)  \n",
       "0                  0.733  Top 200 Consistent (Pre-selected)  \n",
       "1                  0.737  Top 200 Consistent (Pre-selected)  \n",
       "2                  0.612  Top 200 Consistent (Pre-selected)  \n",
       "3                  0.609  Top 200 Consistent (Pre-selected)  \n",
       "4                  0.775  Top 200 Consistent (Pre-selected)  \n",
       "5                  0.816  Top 200 Consistent (Pre-selected)  \n",
       "6                  0.764  Top 200 Consistent (Pre-selected)  \n",
       "7                  0.815  Top 200 Consistent (Pre-selected)  \n",
       "8                  0.802  Top 200 Consistent (Pre-selected)  \n",
       "9                  0.800  Top 200 Consistent (Pre-selected)  \n",
       "10                 0.762  Top 200 Consistent (Pre-selected)  \n",
       "11                 0.760  Top 200 Consistent (Pre-selected)  \n",
       "12                 0.786  Top 200 Consistent (Pre-selected)  \n",
       "13                 0.815  Top 200 Consistent (Pre-selected)  \n",
       "14                 0.789  Top 200 Consistent (Pre-selected)  \n",
       "15                 0.802  Top 200 Consistent (Pre-selected)  \n",
       "16                 0.719  Top 200 Consistent (Pre-selected)  \n",
       "17                 0.790  Top 200 Consistent (Pre-selected)  \n",
       "18                 0.684                      Top 200 Limma  \n",
       "19                 0.683                      Top 200 Limma  \n",
       "20                 0.601                      Top 200 Limma  \n",
       "21                 0.602                      Top 200 Limma  \n",
       "22                 0.716                      Top 200 Limma  \n",
       "23                 0.675                      Top 200 Limma  \n",
       "24                 0.706                      Top 200 Limma  \n",
       "25                 0.677                      Top 200 Limma  \n",
       "26                 0.670                      Top 200 Limma  \n",
       "27                 0.669                      Top 200 Limma  \n",
       "28                 0.726                      Top 200 Limma  \n",
       "29                 0.731                      Top 200 Limma  \n",
       "30                 0.719                      Top 200 Limma  \n",
       "31                 0.681                      Top 200 Limma  \n",
       "32                 0.699                      Top 200 Limma  \n",
       "33                 0.667                      Top 200 Limma  \n",
       "34                 0.718                      Top 200 Limma  \n",
       "35                 0.706                      Top 200 Limma  \n",
       "36                 0.706                      Top 10K Limma  \n",
       "37                 0.707                      Top 10K Limma  \n",
       "38                 0.694                      Top 10K Limma  \n",
       "39                 0.708                      Top 10K Limma  \n",
       "40                 0.701                      Top 10K Limma  \n",
       "41                 0.699                      Top 10K Limma  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas\n",
    "import re\n",
    "from HelperScriptsPY import helper_functions\n",
    "\n",
    "base_dir = \"10_CV_Results_RAWDATA\"\n",
    "ml_files = [base_dir + \"/\" + x for x in os.listdir(base_dir) if re.search(\"ML\", x)]\n",
    "\n",
    "merged_files = []\n",
    "\n",
    "for x in ml_files:\n",
    "    dataset = pandas.read_csv(x)\n",
    "    dataset = helper_functions.drop_useless_column(dataset)\n",
    "    dataset.replace({'model': {\n",
    "        \"SVM_c_RBF_15\": \"SVM (RBF kernel)\",\n",
    "        \"SVM_c\": \"SVM (Linear kernel)\",\n",
    "        \"RidgeLogisticRegr\": \"Logistic regression ('L2')\",\n",
    "        \"RandomForest\": \"Random forest\",\n",
    "        \"LogisticRegr\": \"Logistic regression (no regularization)\",\n",
    "        \"Lasso_classifier\": \"Logistic regression ('L1')\",\n",
    "        \"Elastic_net_classifier\": \"Logistic regression ('L1L2'/Elastic net)\",\n",
    "        \"DecisionTree\": \"Decision tree\"\n",
    "    }}, inplace=True)\n",
    "    merged_files.append(dataset)\n",
    "merged_files = pandas.concat(merged_files)\n",
    "merged_files.columns = [\"Model\", \n",
    "                        \"Methylation value\", \n",
    "                        \"10 CV accuracy (train)\", \n",
    "                        \"10 CV accuracy (hold-out)\", \n",
    "                        \"10 CV AUC (train)\",\n",
    "                        \"10 CV AUC (hold-out)\",\n",
    "                        \"Selected CpGs (features)\"]\n",
    "merged_files = merged_files.reset_index(drop=True)\n",
    "merged_files.loc[:, merged_files.dtypes != \"object\"] = merged_files.loc[:, merged_files.dtypes != \"object\"].round(decimals=3)\n",
    "merged_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Methylation value</th>\n",
       "      <th>10 CV accuracy (train)</th>\n",
       "      <th>10 CV accuracy (hold-out)</th>\n",
       "      <th>10 CV AUC (train)</th>\n",
       "      <th>10 CV AUC (hold-out)</th>\n",
       "      <th>Selected CpGs (features)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DNN classifier</td>\n",
       "      <td>Mval</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.708</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.771</td>\n",
       "      <td>Top 200 Consistent (Pre-selected)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>JointAE-classifier</td>\n",
       "      <td>Mval</td>\n",
       "      <td>0.866</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.724</td>\n",
       "      <td>Top 200 Consistent (Pre-selected)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JointVAE-classifier</td>\n",
       "      <td>Mval</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.772</td>\n",
       "      <td>Top 200 Consistent (Pre-selected)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DNN classifier</td>\n",
       "      <td>Mval</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.638</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.672</td>\n",
       "      <td>Top 200 Limma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JointAE-classifier</td>\n",
       "      <td>Mval</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.647</td>\n",
       "      <td>0.906</td>\n",
       "      <td>0.655</td>\n",
       "      <td>Top 200 Limma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JointVAE-classifier</td>\n",
       "      <td>Mval</td>\n",
       "      <td>0.979</td>\n",
       "      <td>0.628</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.651</td>\n",
       "      <td>Top 200 Limma</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model Methylation value  10 CV accuracy (train)   \n",
       "4       DNN classifier              Mval                   0.999  \\\n",
       "5   JointAE-classifier              Mval                   0.866   \n",
       "1  JointVAE-classifier              Mval                   0.982   \n",
       "3       DNN classifier              Mval                   1.000   \n",
       "2   JointAE-classifier              Mval                   0.874   \n",
       "0  JointVAE-classifier              Mval                   0.979   \n",
       "\n",
       "   10 CV accuracy (hold-out)  10 CV AUC (train)  10 CV AUC (hold-out)   \n",
       "4                      0.708              1.000                 0.771  \\\n",
       "5                      0.711              0.901                 0.724   \n",
       "1                      0.707              0.978                 0.772   \n",
       "3                      0.638              1.000                 0.672   \n",
       "2                      0.647              0.906                 0.655   \n",
       "0                      0.628              0.975                 0.651   \n",
       "\n",
       "            Selected CpGs (features)  \n",
       "4  Top 200 Consistent (Pre-selected)  \n",
       "5  Top 200 Consistent (Pre-selected)  \n",
       "1  Top 200 Consistent (Pre-selected)  \n",
       "3                      Top 200 Limma  \n",
       "2                      Top 200 Limma  \n",
       "0                      Top 200 Limma  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas\n",
    "import re\n",
    "from HelperScriptsPY import helper_functions\n",
    "\n",
    "base_dir = \"10_CV_Results_RAWDATA\"\n",
    "ml_files = [base_dir + \"/\" + x for x in os.listdir(base_dir) if not re.search(\"ML\", x) and not re.search(\".xlsx\", x)]\n",
    "\n",
    "merged_files_DNN = []\n",
    "\n",
    "for x in ml_files:\n",
    "    dataset = pandas.read_csv(x)\n",
    "    dataset = helper_functions.drop_useless_column(dataset)\n",
    "    dataset = dataset[[\"model\", \n",
    "                       \"mval\",\n",
    "                       \"accuracy_train\",\n",
    "                       \"accuracy_test\",\n",
    "                       \"auc_train\",\n",
    "                       \"auc_test\",\n",
    "                       \"cpg_type\"]]\n",
    "    \n",
    "    dataset.replace({'cpg_type': {\n",
    "        \"ALL\":\"Top 200 Limma\",\n",
    "        \"Top_200_all_consistent_CpGs.txt\": \"Top 200 Consistent (Pre-selected)\"\n",
    "    }}, inplace=True)\n",
    "\n",
    "    merged_files_DNN.append(dataset)\n",
    "    \n",
    "merged_files_DNN = pandas.concat(merged_files_DNN)\n",
    "merged_files_DNN.columns = [\"Model\", \n",
    "                        \"Methylation value\", \n",
    "                        \"10 CV accuracy (train)\", \n",
    "                        \"10 CV accuracy (hold-out)\", \n",
    "                        \"10 CV AUC (train)\",\n",
    "                        \"10 CV AUC (hold-out)\",\n",
    "                        \"Selected CpGs (features)\"]\n",
    "merged_files_DNN = merged_files_DNN.reset_index(drop=True)\n",
    "merged_files_DNN.loc[:, merged_files_DNN.dtypes != \"object\"] = merged_files_DNN.loc[:, merged_files_DNN.dtypes != \"object\"].round(decimals=3)\n",
    "merged_files_DNN = merged_files_DNN.sort_values(by=[\"Selected CpGs (features)\", \"Model\"], ascending=True)\n",
    "merged_files_DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Methylation value</th>\n",
       "      <th>10 CV accuracy (train)</th>\n",
       "      <th>10 CV accuracy (hold-out)</th>\n",
       "      <th>10 CV AUC (train)</th>\n",
       "      <th>10 CV AUC (hold-out)</th>\n",
       "      <th>Selected CpGs (features)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic regression ('L1')</td>\n",
       "      <td>Betaval</td>\n",
       "      <td>0.940</td>\n",
       "      <td>0.657</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.694</td>\n",
       "      <td>Top 10K Limma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic regression ('L1')</td>\n",
       "      <td>Mval</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.668</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.708</td>\n",
       "      <td>Top 10K Limma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic regression ('L1L2'/Elastic net)</td>\n",
       "      <td>Betaval</td>\n",
       "      <td>0.971</td>\n",
       "      <td>0.668</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.706</td>\n",
       "      <td>Top 10K Limma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic regression ('L1L2'/Elastic net)</td>\n",
       "      <td>Mval</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.668</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.707</td>\n",
       "      <td>Top 10K Limma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic regression ('L2')</td>\n",
       "      <td>Betaval</td>\n",
       "      <td>0.998</td>\n",
       "      <td>0.660</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.701</td>\n",
       "      <td>Top 10K Limma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Logistic regression ('L2')</td>\n",
       "      <td>Mval</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.667</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.699</td>\n",
       "      <td>Top 10K Limma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>Betaval</td>\n",
       "      <td>0.849</td>\n",
       "      <td>0.679</td>\n",
       "      <td>0.938</td>\n",
       "      <td>0.733</td>\n",
       "      <td>Top 200 Consistent (Pre-selected)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>Mval</td>\n",
       "      <td>0.852</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.938</td>\n",
       "      <td>0.737</td>\n",
       "      <td>Top 200 Consistent (Pre-selected)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DNN classifier</td>\n",
       "      <td>Mval</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.708</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.771</td>\n",
       "      <td>Top 200 Consistent (Pre-selected)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Decision tree</td>\n",
       "      <td>Betaval</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.624</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.612</td>\n",
       "      <td>Top 200 Consistent (Pre-selected)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Decision tree</td>\n",
       "      <td>Mval</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.622</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.609</td>\n",
       "      <td>Top 200 Consistent (Pre-selected)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>JointAE-classifier</td>\n",
       "      <td>Mval</td>\n",
       "      <td>0.866</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.724</td>\n",
       "      <td>Top 200 Consistent (Pre-selected)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>JointVAE-classifier</td>\n",
       "      <td>Mval</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.772</td>\n",
       "      <td>Top 200 Consistent (Pre-selected)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Logistic regression ('L1')</td>\n",
       "      <td>Betaval</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.764</td>\n",
       "      <td>Top 200 Consistent (Pre-selected)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Logistic regression ('L1')</td>\n",
       "      <td>Mval</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.924</td>\n",
       "      <td>0.815</td>\n",
       "      <td>Top 200 Consistent (Pre-selected)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Logistic regression ('L1L2'/Elastic net)</td>\n",
       "      <td>Betaval</td>\n",
       "      <td>0.741</td>\n",
       "      <td>0.712</td>\n",
       "      <td>0.817</td>\n",
       "      <td>0.775</td>\n",
       "      <td>Top 200 Consistent (Pre-selected)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Logistic regression ('L1L2'/Elastic net)</td>\n",
       "      <td>Mval</td>\n",
       "      <td>0.849</td>\n",
       "      <td>0.739</td>\n",
       "      <td>0.926</td>\n",
       "      <td>0.816</td>\n",
       "      <td>Top 200 Consistent (Pre-selected)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Logistic regression ('L2')</td>\n",
       "      <td>Betaval</td>\n",
       "      <td>0.748</td>\n",
       "      <td>0.722</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.786</td>\n",
       "      <td>Top 200 Consistent (Pre-selected)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Logistic regression ('L2')</td>\n",
       "      <td>Mval</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.815</td>\n",
       "      <td>Top 200 Consistent (Pre-selected)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Logistic regression (no regularization)</td>\n",
       "      <td>Betaval</td>\n",
       "      <td>0.852</td>\n",
       "      <td>0.730</td>\n",
       "      <td>0.929</td>\n",
       "      <td>0.802</td>\n",
       "      <td>Top 200 Consistent (Pre-selected)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Logistic regression (no regularization)</td>\n",
       "      <td>Mval</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.932</td>\n",
       "      <td>0.800</td>\n",
       "      <td>Top 200 Consistent (Pre-selected)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Random forest</td>\n",
       "      <td>Betaval</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.707</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.762</td>\n",
       "      <td>Top 200 Consistent (Pre-selected)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Random forest</td>\n",
       "      <td>Mval</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.709</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.760</td>\n",
       "      <td>Top 200 Consistent (Pre-selected)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>SVM (Linear kernel)</td>\n",
       "      <td>Betaval</td>\n",
       "      <td>0.747</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.789</td>\n",
       "      <td>Top 200 Consistent (Pre-selected)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>SVM (Linear kernel)</td>\n",
       "      <td>Mval</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.730</td>\n",
       "      <td>0.920</td>\n",
       "      <td>0.802</td>\n",
       "      <td>Top 200 Consistent (Pre-selected)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>SVM (RBF kernel)</td>\n",
       "      <td>Betaval</td>\n",
       "      <td>0.677</td>\n",
       "      <td>0.677</td>\n",
       "      <td>0.731</td>\n",
       "      <td>0.719</td>\n",
       "      <td>Top 200 Consistent (Pre-selected)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>SVM (RBF kernel)</td>\n",
       "      <td>Mval</td>\n",
       "      <td>0.919</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.790</td>\n",
       "      <td>Top 200 Consistent (Pre-selected)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>Betaval</td>\n",
       "      <td>0.859</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.943</td>\n",
       "      <td>0.684</td>\n",
       "      <td>Top 200 Limma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>Mval</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.649</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.683</td>\n",
       "      <td>Top 200 Limma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>DNN classifier</td>\n",
       "      <td>Mval</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.638</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.672</td>\n",
       "      <td>Top 200 Limma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Decision tree</td>\n",
       "      <td>Betaval</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.614</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.601</td>\n",
       "      <td>Top 200 Limma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Decision tree</td>\n",
       "      <td>Mval</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.615</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.602</td>\n",
       "      <td>Top 200 Limma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>JointAE-classifier</td>\n",
       "      <td>Mval</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.647</td>\n",
       "      <td>0.906</td>\n",
       "      <td>0.655</td>\n",
       "      <td>Top 200 Limma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>JointVAE-classifier</td>\n",
       "      <td>Mval</td>\n",
       "      <td>0.979</td>\n",
       "      <td>0.628</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.651</td>\n",
       "      <td>Top 200 Limma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Logistic regression ('L1')</td>\n",
       "      <td>Betaval</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.666</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.706</td>\n",
       "      <td>Top 200 Limma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Logistic regression ('L1')</td>\n",
       "      <td>Mval</td>\n",
       "      <td>0.807</td>\n",
       "      <td>0.643</td>\n",
       "      <td>0.882</td>\n",
       "      <td>0.677</td>\n",
       "      <td>Top 200 Limma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Logistic regression ('L1L2'/Elastic net)</td>\n",
       "      <td>Betaval</td>\n",
       "      <td>0.749</td>\n",
       "      <td>0.669</td>\n",
       "      <td>0.826</td>\n",
       "      <td>0.716</td>\n",
       "      <td>Top 200 Limma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Logistic regression ('L1L2'/Elastic net)</td>\n",
       "      <td>Mval</td>\n",
       "      <td>0.813</td>\n",
       "      <td>0.646</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.675</td>\n",
       "      <td>Top 200 Limma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Logistic regression ('L2')</td>\n",
       "      <td>Betaval</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.673</td>\n",
       "      <td>0.826</td>\n",
       "      <td>0.719</td>\n",
       "      <td>Top 200 Limma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Logistic regression ('L2')</td>\n",
       "      <td>Mval</td>\n",
       "      <td>0.841</td>\n",
       "      <td>0.648</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.681</td>\n",
       "      <td>Top 200 Limma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Logistic regression (no regularization)</td>\n",
       "      <td>Betaval</td>\n",
       "      <td>0.836</td>\n",
       "      <td>0.638</td>\n",
       "      <td>0.910</td>\n",
       "      <td>0.670</td>\n",
       "      <td>Top 200 Limma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Logistic regression (no regularization)</td>\n",
       "      <td>Mval</td>\n",
       "      <td>0.842</td>\n",
       "      <td>0.633</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.669</td>\n",
       "      <td>Top 200 Limma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Random forest</td>\n",
       "      <td>Betaval</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.680</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.726</td>\n",
       "      <td>Top 200 Limma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Random forest</td>\n",
       "      <td>Mval</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.687</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.731</td>\n",
       "      <td>Top 200 Limma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>SVM (Linear kernel)</td>\n",
       "      <td>Betaval</td>\n",
       "      <td>0.762</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.699</td>\n",
       "      <td>Top 200 Limma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>SVM (Linear kernel)</td>\n",
       "      <td>Mval</td>\n",
       "      <td>0.852</td>\n",
       "      <td>0.635</td>\n",
       "      <td>0.902</td>\n",
       "      <td>0.667</td>\n",
       "      <td>Top 200 Limma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>SVM (RBF kernel)</td>\n",
       "      <td>Betaval</td>\n",
       "      <td>0.678</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.773</td>\n",
       "      <td>0.718</td>\n",
       "      <td>Top 200 Limma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>SVM (RBF kernel)</td>\n",
       "      <td>Mval</td>\n",
       "      <td>0.928</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.706</td>\n",
       "      <td>Top 200 Limma</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Model Methylation value   \n",
       "0                 Logistic regression ('L1')           Betaval  \\\n",
       "1                 Logistic regression ('L1')              Mval   \n",
       "2   Logistic regression ('L1L2'/Elastic net)           Betaval   \n",
       "3   Logistic regression ('L1L2'/Elastic net)              Mval   \n",
       "4                 Logistic regression ('L2')           Betaval   \n",
       "5                 Logistic regression ('L2')              Mval   \n",
       "6                                   AdaBoost           Betaval   \n",
       "7                                   AdaBoost              Mval   \n",
       "8                             DNN classifier              Mval   \n",
       "9                              Decision tree           Betaval   \n",
       "10                             Decision tree              Mval   \n",
       "11                        JointAE-classifier              Mval   \n",
       "12                       JointVAE-classifier              Mval   \n",
       "13                Logistic regression ('L1')           Betaval   \n",
       "14                Logistic regression ('L1')              Mval   \n",
       "15  Logistic regression ('L1L2'/Elastic net)           Betaval   \n",
       "16  Logistic regression ('L1L2'/Elastic net)              Mval   \n",
       "17                Logistic regression ('L2')           Betaval   \n",
       "18                Logistic regression ('L2')              Mval   \n",
       "19   Logistic regression (no regularization)           Betaval   \n",
       "20   Logistic regression (no regularization)              Mval   \n",
       "21                             Random forest           Betaval   \n",
       "22                             Random forest              Mval   \n",
       "23                       SVM (Linear kernel)           Betaval   \n",
       "24                       SVM (Linear kernel)              Mval   \n",
       "25                          SVM (RBF kernel)           Betaval   \n",
       "26                          SVM (RBF kernel)              Mval   \n",
       "27                                  AdaBoost           Betaval   \n",
       "28                                  AdaBoost              Mval   \n",
       "29                            DNN classifier              Mval   \n",
       "30                             Decision tree           Betaval   \n",
       "31                             Decision tree              Mval   \n",
       "32                        JointAE-classifier              Mval   \n",
       "33                       JointVAE-classifier              Mval   \n",
       "34                Logistic regression ('L1')           Betaval   \n",
       "35                Logistic regression ('L1')              Mval   \n",
       "36  Logistic regression ('L1L2'/Elastic net)           Betaval   \n",
       "37  Logistic regression ('L1L2'/Elastic net)              Mval   \n",
       "38                Logistic regression ('L2')           Betaval   \n",
       "39                Logistic regression ('L2')              Mval   \n",
       "40   Logistic regression (no regularization)           Betaval   \n",
       "41   Logistic regression (no regularization)              Mval   \n",
       "42                             Random forest           Betaval   \n",
       "43                             Random forest              Mval   \n",
       "44                       SVM (Linear kernel)           Betaval   \n",
       "45                       SVM (Linear kernel)              Mval   \n",
       "46                          SVM (RBF kernel)           Betaval   \n",
       "47                          SVM (RBF kernel)              Mval   \n",
       "\n",
       "    10 CV accuracy (train)  10 CV accuracy (hold-out)  10 CV AUC (train)   \n",
       "0                    0.940                      0.657              0.987  \\\n",
       "1                    0.999                      0.668              1.000   \n",
       "2                    0.971                      0.668              0.996   \n",
       "3                    1.000                      0.668              1.000   \n",
       "4                    0.998                      0.660              0.999   \n",
       "5                    1.000                      0.667              1.000   \n",
       "6                    0.849                      0.679              0.938   \n",
       "7                    0.852                      0.680              0.938   \n",
       "8                    0.999                      0.708              1.000   \n",
       "9                    1.000                      0.624              1.000   \n",
       "10                   1.000                      0.622              1.000   \n",
       "11                   0.866                      0.711              0.901   \n",
       "12                   0.982                      0.707              0.978   \n",
       "13                   0.738                      0.703              0.814   \n",
       "14                   0.845                      0.738              0.924   \n",
       "15                   0.741                      0.712              0.817   \n",
       "16                   0.849                      0.739              0.926   \n",
       "17                   0.748                      0.722              0.825   \n",
       "18                   0.853                      0.740              0.930   \n",
       "19                   0.852                      0.730              0.929   \n",
       "20                   0.856                      0.732              0.932   \n",
       "21                   1.000                      0.707              1.000   \n",
       "22                   1.000                      0.709              1.000   \n",
       "23                   0.747                      0.710              0.851   \n",
       "24                   0.867                      0.730              0.920   \n",
       "25                   0.677                      0.677              0.731   \n",
       "26                   0.919                      0.727              0.988   \n",
       "27                   0.859                      0.652              0.943   \n",
       "28                   0.870                      0.649              0.950   \n",
       "29                   1.000                      0.638              1.000   \n",
       "30                   1.000                      0.614              1.000   \n",
       "31                   1.000                      0.615              1.000   \n",
       "32                   0.874                      0.647              0.906   \n",
       "33                   0.979                      0.628              0.975   \n",
       "34                   0.754                      0.666              0.830   \n",
       "35                   0.807                      0.643              0.882   \n",
       "36                   0.749                      0.669              0.826   \n",
       "37                   0.813                      0.646              0.887   \n",
       "38                   0.750                      0.673              0.826   \n",
       "39                   0.841                      0.648              0.915   \n",
       "40                   0.836                      0.638              0.910   \n",
       "41                   0.842                      0.633              0.915   \n",
       "42                   1.000                      0.680              1.000   \n",
       "43                   1.000                      0.687              1.000   \n",
       "44                   0.762                      0.675              0.851   \n",
       "45                   0.852                      0.635              0.902   \n",
       "46                   0.678                      0.676              0.773   \n",
       "47                   0.928                      0.676              0.988   \n",
       "\n",
       "    10 CV AUC (hold-out)           Selected CpGs (features)  \n",
       "0                  0.694                      Top 10K Limma  \n",
       "1                  0.708                      Top 10K Limma  \n",
       "2                  0.706                      Top 10K Limma  \n",
       "3                  0.707                      Top 10K Limma  \n",
       "4                  0.701                      Top 10K Limma  \n",
       "5                  0.699                      Top 10K Limma  \n",
       "6                  0.733  Top 200 Consistent (Pre-selected)  \n",
       "7                  0.737  Top 200 Consistent (Pre-selected)  \n",
       "8                  0.771  Top 200 Consistent (Pre-selected)  \n",
       "9                  0.612  Top 200 Consistent (Pre-selected)  \n",
       "10                 0.609  Top 200 Consistent (Pre-selected)  \n",
       "11                 0.724  Top 200 Consistent (Pre-selected)  \n",
       "12                 0.772  Top 200 Consistent (Pre-selected)  \n",
       "13                 0.764  Top 200 Consistent (Pre-selected)  \n",
       "14                 0.815  Top 200 Consistent (Pre-selected)  \n",
       "15                 0.775  Top 200 Consistent (Pre-selected)  \n",
       "16                 0.816  Top 200 Consistent (Pre-selected)  \n",
       "17                 0.786  Top 200 Consistent (Pre-selected)  \n",
       "18                 0.815  Top 200 Consistent (Pre-selected)  \n",
       "19                 0.802  Top 200 Consistent (Pre-selected)  \n",
       "20                 0.800  Top 200 Consistent (Pre-selected)  \n",
       "21                 0.762  Top 200 Consistent (Pre-selected)  \n",
       "22                 0.760  Top 200 Consistent (Pre-selected)  \n",
       "23                 0.789  Top 200 Consistent (Pre-selected)  \n",
       "24                 0.802  Top 200 Consistent (Pre-selected)  \n",
       "25                 0.719  Top 200 Consistent (Pre-selected)  \n",
       "26                 0.790  Top 200 Consistent (Pre-selected)  \n",
       "27                 0.684                      Top 200 Limma  \n",
       "28                 0.683                      Top 200 Limma  \n",
       "29                 0.672                      Top 200 Limma  \n",
       "30                 0.601                      Top 200 Limma  \n",
       "31                 0.602                      Top 200 Limma  \n",
       "32                 0.655                      Top 200 Limma  \n",
       "33                 0.651                      Top 200 Limma  \n",
       "34                 0.706                      Top 200 Limma  \n",
       "35                 0.677                      Top 200 Limma  \n",
       "36                 0.716                      Top 200 Limma  \n",
       "37                 0.675                      Top 200 Limma  \n",
       "38                 0.719                      Top 200 Limma  \n",
       "39                 0.681                      Top 200 Limma  \n",
       "40                 0.670                      Top 200 Limma  \n",
       "41                 0.669                      Top 200 Limma  \n",
       "42                 0.726                      Top 200 Limma  \n",
       "43                 0.731                      Top 200 Limma  \n",
       "44                 0.699                      Top 200 Limma  \n",
       "45                 0.667                      Top 200 Limma  \n",
       "46                 0.718                      Top 200 Limma  \n",
       "47                 0.706                      Top 200 Limma  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_performance_CV10 = pandas.concat([merged_files, merged_files_DNN])\n",
    "final_performance_CV10 = final_performance_CV10.sort_values(by=[\"Selected CpGs (features)\", \"Model\"], ascending=True)\n",
    "final_performance_CV10 = final_performance_CV10.reset_index(drop=True)\n",
    "final_performance_CV10.to_excel(\"10_CV_Results_RAWDATA/Model_performance_10CV_RAWDATA.xlsx\", index=False)\n",
    "final_performance_CV10"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
